{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wcq6dWzy1ZR0",
   "metadata": {
    "id": "wcq6dWzy1ZR0"
   },
   "source": [
    "# Payment Date Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778654e",
   "metadata": {
    "id": "2778654e"
   },
   "source": [
    "\n",
    "### Importing related Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "304c9e38",
   "metadata": {
    "id": "304c9e38"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724f5ee",
   "metadata": {
    "id": "8724f5ee"
   },
   "source": [
    "### Store the dataset into the Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "415db50a",
   "metadata": {
    "id": "415db50a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./h2h_assignment_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e37f05",
   "metadata": {
    "id": "42e37f05"
   },
   "source": [
    "### Check the shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27cc0907",
   "metadata": {
    "id": "27cc0907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 19)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c955d",
   "metadata": {
    "id": "b68c955d"
   },
   "source": [
    "### Check the Detail information of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e092ec9e",
   "metadata": {
    "id": "e092ec9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   business_code           50000 non-null  object \n",
      " 1   cust_number             50000 non-null  object \n",
      " 2   name_customer           50000 non-null  object \n",
      " 3   clear_date              40000 non-null  object \n",
      " 4   buisness_year           50000 non-null  float64\n",
      " 5   doc_id                  50000 non-null  float64\n",
      " 6   posting_date            50000 non-null  object \n",
      " 7   document_create_date    50000 non-null  int64  \n",
      " 8   document_create_date.1  50000 non-null  int64  \n",
      " 9   due_in_date             50000 non-null  float64\n",
      " 10  invoice_currency        50000 non-null  object \n",
      " 11  document type           50000 non-null  object \n",
      " 12  posting_id              50000 non-null  float64\n",
      " 13  area_business           0 non-null      float64\n",
      " 14  total_open_amount       50000 non-null  float64\n",
      " 15  baseline_create_date    50000 non-null  float64\n",
      " 16  cust_payment_terms      50000 non-null  object \n",
      " 17  invoice_id              49994 non-null  float64\n",
      " 18  isOpen                  50000 non-null  int64  \n",
      "dtypes: float64(8), int64(3), object(8)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f2d0e",
   "metadata": {
    "id": "112f2d0e"
   },
   "source": [
    "### Display All the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1416e2fd",
   "metadata": {
    "id": "1416e2fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['business_code', 'cust_number', 'name_customer', 'clear_date',\n       'buisness_year', 'doc_id', 'posting_date', 'document_create_date',\n       'document_create_date.1', 'due_in_date', 'invoice_currency',\n       'document type', 'posting_id', 'area_business', 'total_open_amount',\n       'baseline_create_date', 'cust_payment_terms', 'invoice_id', 'isOpen'],\n      dtype='object')"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465ed7a",
   "metadata": {
    "id": "d465ed7a"
   },
   "source": [
    "### Describe the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25f65e1b",
   "metadata": {
    "id": "25f65e1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       buisness_year        doc_id  document_create_date  \\\ncount   50000.000000  5.000000e+04          5.000000e+04   \nmean     2019.305700  2.012238e+09          2.019351e+07   \nstd         0.460708  2.885235e+08          4.496041e+03   \nmin      2019.000000  1.928502e+09          2.018123e+07   \n25%      2019.000000  1.929342e+09          2.019050e+07   \n50%      2019.000000  1.929964e+09          2.019091e+07   \n75%      2020.000000  1.930619e+09          2.020013e+07   \nmax      2020.000000  9.500000e+09          2.020052e+07   \n\n       document_create_date.1   due_in_date  posting_id  area_business  \\\ncount            5.000000e+04  5.000000e+04     50000.0            0.0   \nmean             2.019354e+07  2.019368e+07         1.0            NaN   \nstd              4.482134e+03  4.470614e+03         0.0            NaN   \nmin              2.018123e+07  2.018122e+07         1.0            NaN   \n25%              2.019051e+07  2.019052e+07         1.0            NaN   \n50%              2.019091e+07  2.019093e+07         1.0            NaN   \n75%              2.020013e+07  2.020022e+07         1.0            NaN   \nmax              2.020052e+07  2.020071e+07         1.0            NaN   \n\n       total_open_amount  baseline_create_date    invoice_id        isOpen  \ncount       50000.000000          5.000000e+04  4.999400e+04  50000.000000  \nmean        32337.021651          2.019354e+07  2.011340e+09      0.200000  \nstd         39205.975231          4.482701e+03  2.766335e+08      0.400004  \nmin             0.720000          2.018121e+07  1.928502e+09      0.000000  \n25%          4928.312500          2.019050e+07  1.929342e+09      0.000000  \n50%         17609.010000          2.019091e+07  1.929964e+09      0.000000  \n75%         47133.635000          2.020013e+07  1.930619e+09      0.000000  \nmax        668593.360000          2.020052e+07  2.960636e+09      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>document_create_date</th>\n      <th>document_create_date.1</th>\n      <th>due_in_date</th>\n      <th>posting_id</th>\n      <th>area_business</th>\n      <th>total_open_amount</th>\n      <th>baseline_create_date</th>\n      <th>invoice_id</th>\n      <th>isOpen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50000.000000</td>\n      <td>5.000000e+04</td>\n      <td>5.000000e+04</td>\n      <td>5.000000e+04</td>\n      <td>5.000000e+04</td>\n      <td>50000.0</td>\n      <td>0.0</td>\n      <td>50000.000000</td>\n      <td>5.000000e+04</td>\n      <td>4.999400e+04</td>\n      <td>50000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2019.305700</td>\n      <td>2.012238e+09</td>\n      <td>2.019351e+07</td>\n      <td>2.019354e+07</td>\n      <td>2.019368e+07</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>32337.021651</td>\n      <td>2.019354e+07</td>\n      <td>2.011340e+09</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.460708</td>\n      <td>2.885235e+08</td>\n      <td>4.496041e+03</td>\n      <td>4.482134e+03</td>\n      <td>4.470614e+03</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>39205.975231</td>\n      <td>4.482701e+03</td>\n      <td>2.766335e+08</td>\n      <td>0.400004</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2019.000000</td>\n      <td>1.928502e+09</td>\n      <td>2.018123e+07</td>\n      <td>2.018123e+07</td>\n      <td>2.018122e+07</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0.720000</td>\n      <td>2.018121e+07</td>\n      <td>1.928502e+09</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2019.000000</td>\n      <td>1.929342e+09</td>\n      <td>2.019050e+07</td>\n      <td>2.019051e+07</td>\n      <td>2.019052e+07</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4928.312500</td>\n      <td>2.019050e+07</td>\n      <td>1.929342e+09</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2019.000000</td>\n      <td>1.929964e+09</td>\n      <td>2.019091e+07</td>\n      <td>2.019091e+07</td>\n      <td>2.019093e+07</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>17609.010000</td>\n      <td>2.019091e+07</td>\n      <td>1.929964e+09</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2020.000000</td>\n      <td>1.930619e+09</td>\n      <td>2.020013e+07</td>\n      <td>2.020013e+07</td>\n      <td>2.020022e+07</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>47133.635000</td>\n      <td>2.020013e+07</td>\n      <td>1.930619e+09</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2020.000000</td>\n      <td>9.500000e+09</td>\n      <td>2.020052e+07</td>\n      <td>2.020052e+07</td>\n      <td>2.020071e+07</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>668593.360000</td>\n      <td>2.020052e+07</td>\n      <td>2.960636e+09</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c8d02",
   "metadata": {
    "id": "0f2c8d02"
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "- Show top 5 records from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f876212",
   "metadata": {
    "id": "8f876212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  business_code cust_number       name_customer           clear_date  \\\n0          U001  0200769623        WAL-MAR corp  2020-02-11 00:00:00   \n1          U001  0200980828              BEN E   2019-08-08 00:00:00   \n2          U001  0200792734          MDV/ trust  2019-12-30 00:00:00   \n3          CA02  0140105686            SYSC llc                  NaN   \n4          U001  0200769623  WAL-MAR foundation  2019-11-25 00:00:00   \n\n   buisness_year        doc_id posting_date  document_create_date  \\\n0         2020.0  1.930438e+09   2020-01-26              20200125   \n1         2019.0  1.929646e+09   2019-07-22              20190722   \n2         2019.0  1.929874e+09   2019-09-14              20190914   \n3         2020.0  2.960623e+09   2020-03-30              20200330   \n4         2019.0  1.930148e+09   2019-11-13              20191113   \n\n   document_create_date.1  due_in_date invoice_currency document type  \\\n0                20200126   20200210.0              USD            RV   \n1                20190722   20190811.0              USD            RV   \n2                20190914   20190929.0              USD            RV   \n3                20200330   20200410.0              CAD            RV   \n4                20191113   20191128.0              USD            RV   \n\n   posting_id  area_business  total_open_amount  baseline_create_date  \\\n0         1.0            NaN           54273.28            20200126.0   \n1         1.0            NaN           79656.60            20190722.0   \n2         1.0            NaN            2253.86            20190914.0   \n3         1.0            NaN            3299.70            20200331.0   \n4         1.0            NaN           33133.29            20191113.0   \n\n  cust_payment_terms    invoice_id  isOpen  \n0               NAH4  1.930438e+09       0  \n1               NAD1  1.929646e+09       0  \n2               NAA8  1.929874e+09       0  \n3               CA10  2.960623e+09       1  \n4               NAH4  1.930148e+09       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>document_create_date</th>\n      <th>document_create_date.1</th>\n      <th>due_in_date</th>\n      <th>invoice_currency</th>\n      <th>document type</th>\n      <th>posting_id</th>\n      <th>area_business</th>\n      <th>total_open_amount</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>invoice_id</th>\n      <th>isOpen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020-02-11 00:00:00</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>20200125</td>\n      <td>20200126</td>\n      <td>20200210.0</td>\n      <td>USD</td>\n      <td>RV</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>54273.28</td>\n      <td>20200126.0</td>\n      <td>NAH4</td>\n      <td>1.930438e+09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019-08-08 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>20190722</td>\n      <td>20190722</td>\n      <td>20190811.0</td>\n      <td>USD</td>\n      <td>RV</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>79656.60</td>\n      <td>20190722.0</td>\n      <td>NAD1</td>\n      <td>1.929646e+09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019-12-30 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>20190914</td>\n      <td>20190914</td>\n      <td>20190929.0</td>\n      <td>USD</td>\n      <td>RV</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2253.86</td>\n      <td>20190914.0</td>\n      <td>NAA8</td>\n      <td>1.929874e+09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>20200330</td>\n      <td>20200330</td>\n      <td>20200410.0</td>\n      <td>CAD</td>\n      <td>RV</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3299.70</td>\n      <td>20200331.0</td>\n      <td>CA10</td>\n      <td>2.960623e+09</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019-11-25 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>20191113</td>\n      <td>20191113</td>\n      <td>20191128.0</td>\n      <td>USD</td>\n      <td>RV</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>33133.29</td>\n      <td>20191113.0</td>\n      <td>NAH4</td>\n      <td>1.930148e+09</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b044e4",
   "metadata": {
    "id": "92b044e4"
   },
   "source": [
    "### Display the Null values percentage against every columns (compare to the total number of records)\n",
    "\n",
    "- Output expected : area_business - 100% null, clear_data = 20% null, invoice_id = 0.012% null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24c7b13d",
   "metadata": {
    "id": "24c7b13d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "area_business             100.000\nclear_date                 20.000\ninvoice_id                  0.012\nbusiness_code               0.000\ninvoice_currency            0.000\ncust_payment_terms          0.000\nbaseline_create_date        0.000\ntotal_open_amount           0.000\nposting_id                  0.000\ndocument type               0.000\ndue_in_date                 0.000\ncust_number                 0.000\ndocument_create_date.1      0.000\ndocument_create_date        0.000\nposting_date                0.000\ndoc_id                      0.000\nbuisness_year               0.000\nname_customer               0.000\nisOpen                      0.000\ndtype: float64"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean().mul(100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46a98b",
   "metadata": {
    "id": "2c46a98b"
   },
   "source": [
    "### Display Invoice_id and Doc_Id\n",
    "\n",
    "- Note - Many of the would have same invoice_id and doc_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "038f24bb",
   "metadata": {
    "id": "038f24bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             doc_id    invoice_id\n0      1.930438e+09  1.930438e+09\n1      1.929646e+09  1.929646e+09\n2      1.929874e+09  1.929874e+09\n3      2.960623e+09  2.960623e+09\n4      1.930148e+09  1.930148e+09\n...             ...           ...\n49995  1.930797e+09  1.930797e+09\n49996  1.929744e+09  1.929744e+09\n49997  1.930537e+09  1.930537e+09\n49998  1.930199e+09  1.930199e+09\n49999  1.928576e+09  1.928576e+09\n\n[50000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_id</th>\n      <th>invoice_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.930438e+09</td>\n      <td>1.930438e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.929646e+09</td>\n      <td>1.929646e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.929874e+09</td>\n      <td>1.929874e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.960623e+09</td>\n      <td>2.960623e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.930148e+09</td>\n      <td>1.930148e+09</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>1.930797e+09</td>\n      <td>1.930797e+09</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>1.929744e+09</td>\n      <td>1.929744e+09</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>1.930537e+09</td>\n      <td>1.930537e+09</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>1.930199e+09</td>\n      <td>1.930199e+09</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>1.928576e+09</td>\n      <td>1.928576e+09</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, [\"doc_id\", \"invoice_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfe10a",
   "metadata": {
    "id": "18cfe10a"
   },
   "source": [
    "#### Write a code to check - 'baseline_create_date',\"document_create_date\",'document_create_date.1' - these columns are almost same.\n",
    "\n",
    "- Please note, if they are same, we need to drop them later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf5b40ff",
   "metadata": {
    "id": "cf5b40ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "baseline_create_date  document_create_date  document_create_date.1\n20181214.0            20190108              20190108                   1\n                      20190201              20190201                   1\n20181230.0            20181226              20181230                   1\n                      20181228              20181230                   1\n                      20181229              20181230                  44\n                                                                      ..\n20200515.0            20200515              20200515                   1\n20200517.0            20200513              20200517                   1\n20200518.0            20200516              20200518                   1\n20200519.0            20200519              20200519                   1\n20200522.0            20200522              20200522                   1\nLength: 5852, dtype: int64"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\n",
    "    [\"baseline_create_date\", \"document_create_date\", \"document_create_date.1\"]\n",
    ").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33110576",
   "metadata": {
    "id": "33110576"
   },
   "source": [
    "#### Please check, Column 'posting_id' is constant columns or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ecce2664",
   "metadata": {
    "id": "ecce2664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['posting_id', 'area_business'], dtype='object')"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.nunique() <= 1]  # Constant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb8daf",
   "metadata": {
    "id": "e5fb8daf"
   },
   "source": [
    "#### Please check 'isOpen' is a constant column and relevant column for this project or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8db9956b",
   "metadata": {
    "id": "8db9956b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['posting_id', 'area_business'], dtype='object')"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.nunique() <= 1]  # Constant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a11a62",
   "metadata": {
    "id": "45a11a62"
   },
   "source": [
    "### Write the code to drop all the following columns from the dataframe\n",
    "\n",
    "- 'area_business'\n",
    "- \"posting_id\"\n",
    "- \"invoice_id\"\n",
    "- \"document_create_date\"\n",
    "- \"isOpen\"\n",
    "- 'document type' \n",
    "- 'document_create_date.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "270d85d1",
   "metadata": {
    "id": "270d85d1"
   },
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    columns=[\n",
    "        \"area_business\",\n",
    "        \"posting_id\",\n",
    "        \"invoice_id\",\n",
    "        \"document_create_date\",\n",
    "        \"isOpen\",\n",
    "        \"document type\",\n",
    "        \"document_create_date.1\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K5LHAM2XVGnk",
   "metadata": {
    "id": "K5LHAM2XVGnk"
   },
   "source": [
    "### Please check from the dataframe whether all the columns are removed or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef3f7d2b",
   "metadata": {
    "id": "ef3f7d2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['business_code', 'cust_number', 'name_customer', 'clear_date',\n       'buisness_year', 'doc_id', 'posting_date', 'due_in_date',\n       'invoice_currency', 'total_open_amount', 'baseline_create_date',\n       'cust_payment_terms'],\n      dtype='object')"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc052c7",
   "metadata": {
    "id": "6bc052c7"
   },
   "source": [
    "### Show all the Dublicate rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ae3c7e4",
   "metadata": {
    "id": "1ae3c7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number        name_customer           clear_date  \\\n1041           U001  0200769623           WAL-MAR in  2019-03-12 00:00:00   \n2400           U001  0200769623        WAL-MAR trust  2019-08-28 00:00:00   \n2584           U001  0200769623  WAL-MAR corporation  2019-12-16 00:00:00   \n3755           U001  0200769623             WAL-MAR   2019-11-22 00:00:00   \n3873           CA02  0140104409       LOB associates                  NaN   \n...             ...         ...                  ...                  ...   \n49928          U001  0200915438           GROC trust  2019-08-15 00:00:00   \n49963          U001  0200759878                SA us  2019-01-29 00:00:00   \n49986          U001  0200772670  ASSOCIAT foundation  2019-06-12 00:00:00   \n49990          U001  0200765011           MAINES llc  2019-06-06 00:00:00   \n49991          U001  0200704045             RA trust  2019-10-25 00:00:00   \n\n       buisness_year        doc_id posting_date  due_in_date invoice_currency  \\\n1041          2019.0  1.928870e+09   2019-02-28   20190315.0              USD   \n2400          2019.0  1.929758e+09   2019-08-18   20190902.0              USD   \n2584          2019.0  1.930217e+09   2019-12-04   20191219.0              USD   \n3755          2019.0  1.930137e+09   2019-11-12   20191127.0              USD   \n3873          2020.0  2.960629e+09   2020-04-14   20200425.0              CAD   \n...              ...           ...          ...          ...              ...   \n49928         2019.0  1.929646e+09   2019-07-25   20190809.0              USD   \n49963         2019.0  1.928614e+09   2019-01-13   20190128.0              USD   \n49986         2019.0  1.929403e+09   2019-05-29   20190613.0              USD   \n49990         2019.0  1.929365e+09   2019-05-22   20190606.0              USD   \n49991         2019.0  1.930001e+09   2019-10-10   20191025.0              USD   \n\n       total_open_amount  baseline_create_date cust_payment_terms  \n1041            19557.41            20190228.0               NAH4  \n2400             5600.41            20190818.0               NAH4  \n2584            35352.17            20191204.0               NAH4  \n3755             2982.64            20191112.0               NAH4  \n3873            82975.82            20200415.0               CA10  \n...                  ...                   ...                ...  \n49928            6969.00            20190725.0               NAA8  \n49963           10968.24            20190113.0               NAH4  \n49986          155837.53            20190529.0               NAU5  \n49990            4008.05            20190522.0               NAA8  \n49991           73002.24            20191010.0               NAA8  \n\n[1161 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>invoice_currency</th>\n      <th>total_open_amount</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1041</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR in</td>\n      <td>2019-03-12 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.928870e+09</td>\n      <td>2019-02-28</td>\n      <td>20190315.0</td>\n      <td>USD</td>\n      <td>19557.41</td>\n      <td>20190228.0</td>\n      <td>NAH4</td>\n    </tr>\n    <tr>\n      <th>2400</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR trust</td>\n      <td>2019-08-28 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.929758e+09</td>\n      <td>2019-08-18</td>\n      <td>20190902.0</td>\n      <td>USD</td>\n      <td>5600.41</td>\n      <td>20190818.0</td>\n      <td>NAH4</td>\n    </tr>\n    <tr>\n      <th>2584</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corporation</td>\n      <td>2019-12-16 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.930217e+09</td>\n      <td>2019-12-04</td>\n      <td>20191219.0</td>\n      <td>USD</td>\n      <td>35352.17</td>\n      <td>20191204.0</td>\n      <td>NAH4</td>\n    </tr>\n    <tr>\n      <th>3755</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR</td>\n      <td>2019-11-22 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.930137e+09</td>\n      <td>2019-11-12</td>\n      <td>20191127.0</td>\n      <td>USD</td>\n      <td>2982.64</td>\n      <td>20191112.0</td>\n      <td>NAH4</td>\n    </tr>\n    <tr>\n      <th>3873</th>\n      <td>CA02</td>\n      <td>0140104409</td>\n      <td>LOB associates</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>2.960629e+09</td>\n      <td>2020-04-14</td>\n      <td>20200425.0</td>\n      <td>CAD</td>\n      <td>82975.82</td>\n      <td>20200415.0</td>\n      <td>CA10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49928</th>\n      <td>U001</td>\n      <td>0200915438</td>\n      <td>GROC trust</td>\n      <td>2019-08-15 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-25</td>\n      <td>20190809.0</td>\n      <td>USD</td>\n      <td>6969.00</td>\n      <td>20190725.0</td>\n      <td>NAA8</td>\n    </tr>\n    <tr>\n      <th>49963</th>\n      <td>U001</td>\n      <td>0200759878</td>\n      <td>SA us</td>\n      <td>2019-01-29 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.928614e+09</td>\n      <td>2019-01-13</td>\n      <td>20190128.0</td>\n      <td>USD</td>\n      <td>10968.24</td>\n      <td>20190113.0</td>\n      <td>NAH4</td>\n    </tr>\n    <tr>\n      <th>49986</th>\n      <td>U001</td>\n      <td>0200772670</td>\n      <td>ASSOCIAT foundation</td>\n      <td>2019-06-12 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.929403e+09</td>\n      <td>2019-05-29</td>\n      <td>20190613.0</td>\n      <td>USD</td>\n      <td>155837.53</td>\n      <td>20190529.0</td>\n      <td>NAU5</td>\n    </tr>\n    <tr>\n      <th>49990</th>\n      <td>U001</td>\n      <td>0200765011</td>\n      <td>MAINES llc</td>\n      <td>2019-06-06 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.929365e+09</td>\n      <td>2019-05-22</td>\n      <td>20190606.0</td>\n      <td>USD</td>\n      <td>4008.05</td>\n      <td>20190522.0</td>\n      <td>NAA8</td>\n    </tr>\n    <tr>\n      <th>49991</th>\n      <td>U001</td>\n      <td>0200704045</td>\n      <td>RA trust</td>\n      <td>2019-10-25 00:00:00</td>\n      <td>2019.0</td>\n      <td>1.930001e+09</td>\n      <td>2019-10-10</td>\n      <td>20191025.0</td>\n      <td>USD</td>\n      <td>73002.24</td>\n      <td>20191010.0</td>\n      <td>NAA8</td>\n    </tr>\n  </tbody>\n</table>\n<p>1161 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fab09",
   "metadata": {
    "id": "464fab09"
   },
   "source": [
    "### Display the Number of Dublicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1ea2397",
   "metadata": {
    "id": "b1ea2397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "50000"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a6718",
   "metadata": {
    "id": "827a6718"
   },
   "source": [
    "### Drop all the Dublicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d10151c",
   "metadata": {
    "id": "5d10151c"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d1f9b",
   "metadata": {
    "id": "7e5d1f9b"
   },
   "source": [
    "#### Now check for all dublicate rows now\n",
    "\n",
    "- Note - It must be 0 by now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9accc9fc",
   "metadata": {
    "id": "9accc9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [business_code, cust_number, name_customer, clear_date, buisness_year, doc_id, posting_date, due_in_date, invoice_currency, total_open_amount, baseline_create_date, cust_payment_terms]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>invoice_currency</th>\n      <th>total_open_amount</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]  # It is 0 indeed, all duplicate rows have been dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0704898",
   "metadata": {
    "id": "d0704898"
   },
   "source": [
    "### Check for the number of Rows and Columns in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "582748a8",
   "metadata": {
    "id": "582748a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "48839"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4o9c5UodWRtl",
   "metadata": {
    "id": "4o9c5UodWRtl"
   },
   "source": [
    "### Find out the total count of null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b0612cb5",
   "metadata": {
    "id": "b0612cb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "business_code              0\ncust_number                0\nname_customer              0\nclear_date              9681\nbuisness_year              0\ndoc_id                     0\nposting_date               0\ndue_in_date                0\ninvoice_currency           0\ntotal_open_amount          0\nbaseline_create_date       0\ncust_payment_terms         0\ndtype: int64"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdb98b",
   "metadata": {
    "id": "7abdb98b"
   },
   "source": [
    "# Data type Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPfSUSp-WpPj",
   "metadata": {
    "id": "LPfSUSp-WpPj"
   },
   "source": [
    "### Please check the data type of each column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "689c8592",
   "metadata": {
    "id": "689c8592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "business_code            object\ncust_number              object\nname_customer            object\nclear_date               object\nbuisness_year           float64\ndoc_id                  float64\nposting_date             object\ndue_in_date             float64\ninvoice_currency         object\ntotal_open_amount       float64\nbaseline_create_date    float64\ncust_payment_terms       object\ndtype: object"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nsem0_3XzOt",
   "metadata": {
    "id": "0nsem0_3XzOt"
   },
   "source": [
    "### Check the datatype format of below columns\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "-yyODyW3X6pL",
   "metadata": {
    "id": "-yyODyW3X6pL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "clear_date               object\nposting_date             object\ndue_in_date             float64\nbaseline_create_date    float64\ndtype: object"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    ":, [\"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\"]\n",
    "].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf9478",
   "metadata": {
    "id": "11cf9478"
   },
   "source": [
    "### converting date columns into date time formats\n",
    "\n",
    "- clear_date  \n",
    "- posting_date\n",
    "- due_in_date \n",
    "- baseline_create_date\n",
    "\n",
    "\n",
    "- **Note - You have to convert all these above columns into \"%Y%m%d\" format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "dt_lis = [\"baseline_create_date\", \"due_in_date\", \"clear_date\", \"posting_date\"]\n",
    "df[dt_lis[0]], df[dt_lis[1]] = df[dt_lis[0]].astype(\"int\"), df[\n",
    "    dt_lis[1]\n",
    "].astype(\"int\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "df[dt_lis[0]], df[dt_lis[1]] = (\n",
    "    pd.to_datetime(df[dt_lis[0]], format=\"%Y%m%d\").dt.date,\n",
    "    pd.to_datetime(df[dt_lis[1]], format=\"%Y%m%d\").dt.date,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "df[dt_lis[2]], df[dt_lis[3]] = (\n",
    "    pd.to_datetime(df[dt_lis[2]], format=\"%Y-%m-%d\").dt.date,\n",
    "    pd.to_datetime(df[dt_lis[3]], format=\"%Y-%m-%d\").dt.date,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "      baseline_create_date due_in_date  clear_date posting_date\n0               2020-01-26  2020-02-10  2020-02-11   2020-01-26\n1               2019-07-22  2019-08-11  2019-08-08   2019-07-22\n2               2019-09-14  2019-09-29  2019-12-30   2019-09-14\n3               2020-03-31  2020-04-10         NaT   2020-03-30\n4               2019-11-13  2019-11-28  2019-11-25   2019-11-13\n...                    ...         ...         ...          ...\n49995           2020-04-21  2020-05-06         NaT   2020-04-21\n49996           2019-08-15  2019-08-30  2019-09-03   2019-08-15\n49997           2020-02-19  2020-03-05  2020-03-05   2020-02-19\n49998           2019-11-27  2019-12-12  2019-12-12   2019-11-27\n49999           2019-01-01  2019-01-24  2019-01-15   2019-01-05\n\n[48839 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>baseline_create_date</th>\n      <th>due_in_date</th>\n      <th>clear_date</th>\n      <th>posting_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-02-11</td>\n      <td>2020-01-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-08-08</td>\n      <td>2019-07-22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-12-30</td>\n      <td>2019-09-14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-03-31</td>\n      <td>2020-04-10</td>\n      <td>NaT</td>\n      <td>2020-03-30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-25</td>\n      <td>2019-11-13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>2020-04-21</td>\n      <td>2020-05-06</td>\n      <td>NaT</td>\n      <td>2020-04-21</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>2019-08-15</td>\n      <td>2019-08-30</td>\n      <td>2019-09-03</td>\n      <td>2019-08-15</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>2020-02-19</td>\n      <td>2020-03-05</td>\n      <td>2020-03-05</td>\n      <td>2020-02-19</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>2019-11-27</td>\n      <td>2019-12-12</td>\n      <td>2019-12-12</td>\n      <td>2019-11-27</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>2019-01-01</td>\n      <td>2019-01-24</td>\n      <td>2019-01-15</td>\n      <td>2019-01-05</td>\n    </tr>\n  </tbody>\n</table>\n<p>48839 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, dt_lis]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "7adq0wSIYSCS",
   "metadata": {
    "id": "7adq0wSIYSCS"
   },
   "source": [
    "### Please check the datatype of all the columns after conversion of the above 4 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd028c61",
   "metadata": {
    "id": "fd028c61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "business_code            object\ncust_number              object\nname_customer            object\nclear_date               object\nbuisness_year           float64\ndoc_id                  float64\nposting_date             object\ndue_in_date              object\ninvoice_currency         object\ntotal_open_amount       float64\nbaseline_create_date     object\ncust_payment_terms       object\ndtype: object"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9882fa",
   "metadata": {
    "id": "8c9882fa"
   },
   "source": [
    "#### the invoice_currency column contains two different categories, USD and CAD\n",
    "\n",
    "- Please do a count of each currency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72085397",
   "metadata": {
    "id": "72085397"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "USD    45011\nCAD     3828\nName: invoice_currency, dtype: int64"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['invoice_currency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe26ee",
   "metadata": {
    "id": "6cbe26ee"
   },
   "source": [
    "#### display the \"total_open_amount\" column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c49f2ab",
   "metadata": {
    "id": "6c49f2ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0        54273.28\n1        79656.60\n2         2253.86\n3         3299.70\n4        33133.29\n           ...   \n49995     3187.86\n49996     6766.54\n49997     6120.86\n49998       63.48\n49999     1790.30\nName: total_open_amount, Length: 48839, dtype: float64"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"total_open_amount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df899966",
   "metadata": {
    "id": "df899966"
   },
   "source": [
    "### Convert all CAD into USD currency of \"total_open_amount\" column\n",
    "\n",
    "- 1 CAD = 0.7 USD\n",
    "- Create a new column i.e \"converted_usd\" and store USD and convered CAD to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8eb2f1c5",
   "metadata": {
    "id": "8eb2f1c5"
   },
   "outputs": [],
   "source": [
    "df[\"converted_usd\"] = np.where(\n",
    "    (df[\"invoice_currency\"] == \"CAD\"),\n",
    "    df[\"total_open_amount\"] * 0.7,\n",
    "    df[\"total_open_amount\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6ef1d",
   "metadata": {
    "id": "f9f6ef1d"
   },
   "source": [
    "### Display the new \"converted_usd\" column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1fc1a178",
   "metadata": {
    "id": "1fc1a178"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  invoice_currency  total_open_amount  converted_usd\n0              USD           54273.28      54273.280\n1              USD           79656.60      79656.600\n2              USD            2253.86       2253.860\n3              CAD            3299.70       2309.790\n4              USD           33133.29      33133.290\n5              CAD           22225.84      15558.088\n6              USD            7358.49       7358.490\n7              USD           11173.02      11173.020\n8              USD           15995.04      15995.040\n9              USD              28.63         28.630",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>invoice_currency</th>\n      <th>total_open_amount</th>\n      <th>converted_usd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>USD</td>\n      <td>54273.28</td>\n      <td>54273.280</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>USD</td>\n      <td>79656.60</td>\n      <td>79656.600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USD</td>\n      <td>2253.86</td>\n      <td>2253.860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CAD</td>\n      <td>3299.70</td>\n      <td>2309.790</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USD</td>\n      <td>33133.29</td>\n      <td>33133.290</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CAD</td>\n      <td>22225.84</td>\n      <td>15558.088</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>USD</td>\n      <td>7358.49</td>\n      <td>7358.490</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>USD</td>\n      <td>11173.02</td>\n      <td>11173.020</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>USD</td>\n      <td>15995.04</td>\n      <td>15995.040</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>USD</td>\n      <td>28.63</td>\n      <td>28.630</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "0:9,\n",
    "[\n",
    "    \"invoice_currency\",\n",
    "    \"total_open_amount\",\n",
    "    \"converted_usd\",\n",
    "],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6XLXX17kayuy",
   "metadata": {
    "id": "6XLXX17kayuy"
   },
   "source": [
    "### Display year wise total number of record \n",
    "\n",
    "- Note -  use \"buisness_year\" column for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00c9f6ee",
   "metadata": {
    "id": "00c9f6ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2019.0    33975\n2020.0    14864\nName: buisness_year, dtype: int64"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['buisness_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c35904",
   "metadata": {
    "id": "05c35904"
   },
   "source": [
    "### Write the code to delete the following columns \n",
    "\n",
    "- 'invoice_currency'\n",
    "- 'total_open_amount', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ac28aa5",
   "metadata": {
    "id": "4ac28aa5"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\"invoice_currency\", \"total_open_amount\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bDBJ_Kvwc086",
   "metadata": {
    "id": "bDBJ_Kvwc086"
   },
   "source": [
    "### Write a code to check the number of columns in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ea360a8c",
   "metadata": {
    "id": "ea360a8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "11"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f63655",
   "metadata": {
    "id": "b8f63655"
   },
   "source": [
    "# Splitting the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f749d",
   "metadata": {
    "id": "a00f749d"
   },
   "source": [
    "### Look for all columns containing null value\n",
    "\n",
    "- Note - Output expected is only one column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "148c801e",
   "metadata": {
    "id": "148c801e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['clear_date']"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_columns = df.columns[df.isna().any()].tolist()\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094a290",
   "metadata": {
    "id": "a094a290"
   },
   "source": [
    "#### Find out the number of null values from the column that you got from the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "30bfb113",
   "metadata": {
    "id": "30bfb113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "clear_date    9681\ndtype: int64"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[null_columns].isna().sum()  # 9681 rows of null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d939b",
   "metadata": {
    "id": "7f6d939b"
   },
   "source": [
    "### On basis of the above column we are spliting data into dataset\n",
    "\n",
    "- First dataframe (refer that as maindata) only containing the rows, that have NULL data in that column ( This is going to be our train dataset ) \n",
    "- Second dataframe (refer that as nulldata) that contains the columns, that have Not Null data in that column ( This is going to be our test dataset ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8764c33",
   "metadata": {
    "id": "c8764c33"
   },
   "outputs": [],
   "source": [
    "filter = df[null_columns[0]].isna()\n",
    "maindata = df[filter]\n",
    "nulldata = df[~filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3P8riRBHd_r6",
   "metadata": {
    "id": "3P8riRBHd_r6"
   },
   "source": [
    "### Check the number of Rows and Columns for both the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "(9681, 11)"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindata.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "0693a464",
   "metadata": {
    "id": "0693a464",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f86bc74",
   "metadata": {
    "id": "7f86bc74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(39158, 11)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulldata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747165d",
   "metadata": {
    "id": "0747165d"
   },
   "source": [
    "### Display the 5 records from maindata and nulldata dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dec2ec36",
   "metadata": {
    "id": "dec2ec36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   business_code cust_number     name_customer clear_date  buisness_year  \\\n3           CA02  0140105686          SYSC llc        NaT         2020.0   \n7           U001  0200744019           TARG us        NaT         2020.0   \n10          U001  0200418007               AM         NaT         2020.0   \n14          U001  0200739534        OK systems        NaT         2020.0   \n15          U001  0200353024  DECA corporation        NaT         2020.0   \n\n          doc_id posting_date due_in_date baseline_create_date  \\\n3   2.960623e+09   2020-03-30  2020-04-10           2020-03-31   \n7   1.930659e+09   2020-03-19  2020-04-03           2020-03-19   \n10  1.930611e+09   2020-03-11  2020-03-26           2020-03-11   \n14  1.930788e+09   2020-04-15  2020-04-30           2020-04-15   \n15  1.930817e+09   2020-04-23  2020-04-26           2020-04-16   \n\n   cust_payment_terms  converted_usd  \n3                CA10        2309.79  \n7                NAA8       11173.02  \n10               NAA8        3525.59  \n14               NAA8      121105.65  \n15               NAM2        3726.06  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>2020-04-10</td>\n      <td>2020-03-31</td>\n      <td>CA10</td>\n      <td>2309.79</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>U001</td>\n      <td>0200744019</td>\n      <td>TARG us</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930659e+09</td>\n      <td>2020-03-19</td>\n      <td>2020-04-03</td>\n      <td>2020-03-19</td>\n      <td>NAA8</td>\n      <td>11173.02</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>U001</td>\n      <td>0200418007</td>\n      <td>AM</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930611e+09</td>\n      <td>2020-03-11</td>\n      <td>2020-03-26</td>\n      <td>2020-03-11</td>\n      <td>NAA8</td>\n      <td>3525.59</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>U001</td>\n      <td>0200739534</td>\n      <td>OK systems</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930788e+09</td>\n      <td>2020-04-15</td>\n      <td>2020-04-30</td>\n      <td>2020-04-15</td>\n      <td>NAA8</td>\n      <td>121105.65</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>U001</td>\n      <td>0200353024</td>\n      <td>DECA corporation</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930817e+09</td>\n      <td>2020-04-23</td>\n      <td>2020-04-26</td>\n      <td>2020-04-16</td>\n      <td>NAM2</td>\n      <td>3726.06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eee2d68a",
   "metadata": {
    "id": "eee2d68a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  business_code cust_number       name_customer  clear_date  buisness_year  \\\n0          U001  0200769623        WAL-MAR corp  2020-02-11         2020.0   \n1          U001  0200980828              BEN E   2019-08-08         2019.0   \n2          U001  0200792734          MDV/ trust  2019-12-30         2019.0   \n4          U001  0200769623  WAL-MAR foundation  2019-11-25         2019.0   \n5          CA02  0140106181    THE  corporation  2019-12-04         2019.0   \n\n         doc_id posting_date due_in_date baseline_create_date  \\\n0  1.930438e+09   2020-01-26  2020-02-10           2020-01-26   \n1  1.929646e+09   2019-07-22  2019-08-11           2019-07-22   \n2  1.929874e+09   2019-09-14  2019-09-29           2019-09-14   \n4  1.930148e+09   2019-11-13  2019-11-28           2019-11-13   \n5  2.960581e+09   2019-09-20  2019-10-04           2019-09-24   \n\n  cust_payment_terms  converted_usd  \n0               NAH4      54273.280  \n1               NAD1      79656.600  \n2               NAA8       2253.860  \n4               NAH4      33133.290  \n5               CA10      15558.088  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020-02-11</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-01-26</td>\n      <td>NAH4</td>\n      <td>54273.280</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019-08-08</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-07-22</td>\n      <td>NAD1</td>\n      <td>79656.600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019-12-30</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-09-14</td>\n      <td>NAA8</td>\n      <td>2253.860</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019-11-25</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAH4</td>\n      <td>33133.290</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CA02</td>\n      <td>0140106181</td>\n      <td>THE  corporation</td>\n      <td>2019-12-04</td>\n      <td>2019.0</td>\n      <td>2.960581e+09</td>\n      <td>2019-09-20</td>\n      <td>2019-10-04</td>\n      <td>2019-09-24</td>\n      <td>CA10</td>\n      <td>15558.088</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulldata.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa6746",
   "metadata": {
    "id": "24aa6746"
   },
   "source": [
    "## Considering the **maindata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c4aa7",
   "metadata": {
    "id": "f92c4aa7"
   },
   "source": [
    "#### Generate a new column \"Delay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to create a new column 'Delay' from two existing columns, \"clear_date\" and \"due_in_date\" \n",
    "- Formula - Delay = clear_date - due_in_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8eeceb9c",
   "metadata": {
    "id": "8eeceb9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number       name_customer  clear_date  \\\n0              U001  0200769623        WAL-MAR corp  2020-02-11   \n1              U001  0200980828              BEN E   2019-08-08   \n2              U001  0200792734          MDV/ trust  2019-12-30   \n3              CA02  0140105686            SYSC llc         NaT   \n4              U001  0200769623  WAL-MAR foundation  2019-11-25   \n...             ...         ...                 ...         ...   \n49995          U001  0200561861      CO corporation         NaT   \n49996          U001  0200769623          WAL-MAR co  2019-09-03   \n49997          U001  0200772595    SAFEW associates  2020-03-05   \n49998          U001  0200726979           BJ'S  llc  2019-12-12   \n49999          U001  0200020431            DEC corp  2019-01-15   \n\n       buisness_year        doc_id posting_date due_in_date  \\\n0             2020.0  1.930438e+09   2020-01-26  2020-02-10   \n1             2019.0  1.929646e+09   2019-07-22  2019-08-11   \n2             2019.0  1.929874e+09   2019-09-14  2019-09-29   \n3             2020.0  2.960623e+09   2020-03-30  2020-04-10   \n4             2019.0  1.930148e+09   2019-11-13  2019-11-28   \n...              ...           ...          ...         ...   \n49995         2020.0  1.930797e+09   2020-04-21  2020-05-06   \n49996         2019.0  1.929744e+09   2019-08-15  2019-08-30   \n49997         2020.0  1.930537e+09   2020-02-19  2020-03-05   \n49998         2019.0  1.930199e+09   2019-11-27  2019-12-12   \n49999         2019.0  1.928576e+09   2019-01-05  2019-01-24   \n\n      baseline_create_date cust_payment_terms  converted_usd   Delay  \n0               2020-01-26               NAH4       54273.28  1 days  \n1               2019-07-22               NAD1       79656.60 -3 days  \n2               2019-09-14               NAA8        2253.86 92 days  \n3               2020-03-31               CA10        2309.79     NaT  \n4               2019-11-13               NAH4       33133.29 -3 days  \n...                    ...                ...            ...     ...  \n49995           2020-04-21               NAA8        3187.86     NaT  \n49996           2019-08-15               NAH4        6766.54  4 days  \n49997           2020-02-19               NAA8        6120.86  0 days  \n49998           2019-11-27               NAA8          63.48  0 days  \n49999           2019-01-01               NAM4        1790.30 -9 days  \n\n[48839 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n      <th>Delay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020-02-11</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-01-26</td>\n      <td>NAH4</td>\n      <td>54273.28</td>\n      <td>1 days</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019-08-08</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-07-22</td>\n      <td>NAD1</td>\n      <td>79656.60</td>\n      <td>-3 days</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019-12-30</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-09-14</td>\n      <td>NAA8</td>\n      <td>2253.86</td>\n      <td>92 days</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>2020-04-10</td>\n      <td>2020-03-31</td>\n      <td>CA10</td>\n      <td>2309.79</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019-11-25</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAH4</td>\n      <td>33133.29</td>\n      <td>-3 days</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>U001</td>\n      <td>0200561861</td>\n      <td>CO corporation</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930797e+09</td>\n      <td>2020-04-21</td>\n      <td>2020-05-06</td>\n      <td>2020-04-21</td>\n      <td>NAA8</td>\n      <td>3187.86</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR co</td>\n      <td>2019-09-03</td>\n      <td>2019.0</td>\n      <td>1.929744e+09</td>\n      <td>2019-08-15</td>\n      <td>2019-08-30</td>\n      <td>2019-08-15</td>\n      <td>NAH4</td>\n      <td>6766.54</td>\n      <td>4 days</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>U001</td>\n      <td>0200772595</td>\n      <td>SAFEW associates</td>\n      <td>2020-03-05</td>\n      <td>2020.0</td>\n      <td>1.930537e+09</td>\n      <td>2020-02-19</td>\n      <td>2020-03-05</td>\n      <td>2020-02-19</td>\n      <td>NAA8</td>\n      <td>6120.86</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>U001</td>\n      <td>0200726979</td>\n      <td>BJ'S  llc</td>\n      <td>2019-12-12</td>\n      <td>2019.0</td>\n      <td>1.930199e+09</td>\n      <td>2019-11-27</td>\n      <td>2019-12-12</td>\n      <td>2019-11-27</td>\n      <td>NAA8</td>\n      <td>63.48</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>U001</td>\n      <td>0200020431</td>\n      <td>DEC corp</td>\n      <td>2019-01-15</td>\n      <td>2019.0</td>\n      <td>1.928576e+09</td>\n      <td>2019-01-05</td>\n      <td>2019-01-24</td>\n      <td>2019-01-01</td>\n      <td>NAM4</td>\n      <td>1790.30</td>\n      <td>-9 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>48839 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Delay'] = df['clear_date'] - df['due_in_date']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482144e",
   "metadata": {
    "id": "f482144e"
   },
   "source": [
    "### Generate a new column \"avgdelay\" from the existing columns\n",
    "\n",
    "- Note - You are expected to make a new column \"avgdelay\" by grouping \"name_customer\" column with reapect to mean of the \"Delay\" column.\n",
    "- This new column \"avg_delay\" is meant to store \"customer_name\" wise delay\n",
    "- groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
    "- Display the new \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number       name_customer  clear_date  \\\n0              U001  0200769623        WAL-MAR corp  2020-02-11   \n1              U001  0200980828              BEN E   2019-08-08   \n2              U001  0200792734          MDV/ trust  2019-12-30   \n3              CA02  0140105686            SYSC llc         NaT   \n4              U001  0200769623  WAL-MAR foundation  2019-11-25   \n...             ...         ...                 ...         ...   \n49995          U001  0200561861      CO corporation         NaT   \n49996          U001  0200769623          WAL-MAR co  2019-09-03   \n49997          U001  0200772595    SAFEW associates  2020-03-05   \n49998          U001  0200726979           BJ'S  llc  2019-12-12   \n49999          U001  0200020431            DEC corp  2019-01-15   \n\n       buisness_year        doc_id posting_date due_in_date  \\\n0             2020.0  1.930438e+09   2020-01-26  2020-02-10   \n1             2019.0  1.929646e+09   2019-07-22  2019-08-11   \n2             2019.0  1.929874e+09   2019-09-14  2019-09-29   \n3             2020.0  2.960623e+09   2020-03-30  2020-04-10   \n4             2019.0  1.930148e+09   2019-11-13  2019-11-28   \n...              ...           ...          ...         ...   \n49995         2020.0  1.930797e+09   2020-04-21  2020-05-06   \n49996         2019.0  1.929744e+09   2019-08-15  2019-08-30   \n49997         2020.0  1.930537e+09   2020-02-19  2020-03-05   \n49998         2019.0  1.930199e+09   2019-11-27  2019-12-12   \n49999         2019.0  1.928576e+09   2019-01-05  2019-01-24   \n\n      baseline_create_date cust_payment_terms  converted_usd   Delay  \\\n0               2020-01-26               NAH4       54273.28  1 days   \n1               2019-07-22               NAD1       79656.60 -3 days   \n2               2019-09-14               NAA8        2253.86 92 days   \n3               2020-03-31               CA10        2309.79     NaT   \n4               2019-11-13               NAH4       33133.29 -3 days   \n...                    ...                ...            ...     ...   \n49995           2020-04-21               NAA8        3187.86     NaT   \n49996           2019-08-15               NAH4        6766.54  4 days   \n49997           2020-02-19               NAA8        6120.86  0 days   \n49998           2019-11-27               NAA8          63.48  0 days   \n49999           2019-01-01               NAM4        1790.30 -9 days   \n\n                         avgdelay  \n0     -3 days +07:08:49.779837776  \n1                19 days 00:00:00  \n2       8 days 02:10:54.545454545  \n3       2 days 19:03:31.764705882  \n4     -3 days +19:33:27.692307693  \n...                           ...  \n49995 -1 days +17:08:34.285714286  \n49996 -3 days +12:40:08.540925267  \n49997   1 days 01:08:34.285714285  \n49998   1 days 13:36:42.985074626  \n49999 -4 days +02:20:52.173913044  \n\n[48839 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n      <th>Delay</th>\n      <th>avgdelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020-02-11</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-01-26</td>\n      <td>NAH4</td>\n      <td>54273.28</td>\n      <td>1 days</td>\n      <td>-3 days +07:08:49.779837776</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019-08-08</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-07-22</td>\n      <td>NAD1</td>\n      <td>79656.60</td>\n      <td>-3 days</td>\n      <td>19 days 00:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019-12-30</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-09-14</td>\n      <td>NAA8</td>\n      <td>2253.86</td>\n      <td>92 days</td>\n      <td>8 days 02:10:54.545454545</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>2020-04-10</td>\n      <td>2020-03-31</td>\n      <td>CA10</td>\n      <td>2309.79</td>\n      <td>NaT</td>\n      <td>2 days 19:03:31.764705882</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019-11-25</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAH4</td>\n      <td>33133.29</td>\n      <td>-3 days</td>\n      <td>-3 days +19:33:27.692307693</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>U001</td>\n      <td>0200561861</td>\n      <td>CO corporation</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930797e+09</td>\n      <td>2020-04-21</td>\n      <td>2020-05-06</td>\n      <td>2020-04-21</td>\n      <td>NAA8</td>\n      <td>3187.86</td>\n      <td>NaT</td>\n      <td>-1 days +17:08:34.285714286</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR co</td>\n      <td>2019-09-03</td>\n      <td>2019.0</td>\n      <td>1.929744e+09</td>\n      <td>2019-08-15</td>\n      <td>2019-08-30</td>\n      <td>2019-08-15</td>\n      <td>NAH4</td>\n      <td>6766.54</td>\n      <td>4 days</td>\n      <td>-3 days +12:40:08.540925267</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>U001</td>\n      <td>0200772595</td>\n      <td>SAFEW associates</td>\n      <td>2020-03-05</td>\n      <td>2020.0</td>\n      <td>1.930537e+09</td>\n      <td>2020-02-19</td>\n      <td>2020-03-05</td>\n      <td>2020-02-19</td>\n      <td>NAA8</td>\n      <td>6120.86</td>\n      <td>0 days</td>\n      <td>1 days 01:08:34.285714285</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>U001</td>\n      <td>0200726979</td>\n      <td>BJ'S  llc</td>\n      <td>2019-12-12</td>\n      <td>2019.0</td>\n      <td>1.930199e+09</td>\n      <td>2019-11-27</td>\n      <td>2019-12-12</td>\n      <td>2019-11-27</td>\n      <td>NAA8</td>\n      <td>63.48</td>\n      <td>0 days</td>\n      <td>1 days 13:36:42.985074626</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>U001</td>\n      <td>0200020431</td>\n      <td>DEC corp</td>\n      <td>2019-01-15</td>\n      <td>2019.0</td>\n      <td>1.928576e+09</td>\n      <td>2019-01-05</td>\n      <td>2019-01-24</td>\n      <td>2019-01-01</td>\n      <td>NAM4</td>\n      <td>1790.30</td>\n      <td>-9 days</td>\n      <td>-4 days +02:20:52.173913044</td>\n    </tr>\n  </tbody>\n</table>\n<p>48839 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avgdelay'] = df.groupby('name_customer')['Delay'].transform('mean')\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You need to add the \"avg_delay\" column with the maindata, mapped with \"name_customer\" column\n",
    "\n",
    " - Note - You need to use map function to map the avgdelay with respect to \"name_customer\" column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e1e1f3d9",
   "metadata": {
    "id": "e1e1f3d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number       name_customer  clear_date  \\\n0              U001  0200769623        WAL-MAR corp  2020-02-11   \n1              U001  0200980828              BEN E   2019-08-08   \n2              U001  0200792734          MDV/ trust  2019-12-30   \n3              CA02  0140105686            SYSC llc         NaT   \n4              U001  0200769623  WAL-MAR foundation  2019-11-25   \n...             ...         ...                 ...         ...   \n49995          U001  0200561861      CO corporation         NaT   \n49996          U001  0200769623          WAL-MAR co  2019-09-03   \n49997          U001  0200772595    SAFEW associates  2020-03-05   \n49998          U001  0200726979           BJ'S  llc  2019-12-12   \n49999          U001  0200020431            DEC corp  2019-01-15   \n\n       buisness_year        doc_id posting_date due_in_date  \\\n0             2020.0  1.930438e+09   2020-01-26  2020-02-10   \n1             2019.0  1.929646e+09   2019-07-22  2019-08-11   \n2             2019.0  1.929874e+09   2019-09-14  2019-09-29   \n3             2020.0  2.960623e+09   2020-03-30  2020-04-10   \n4             2019.0  1.930148e+09   2019-11-13  2019-11-28   \n...              ...           ...          ...         ...   \n49995         2020.0  1.930797e+09   2020-04-21  2020-05-06   \n49996         2019.0  1.929744e+09   2019-08-15  2019-08-30   \n49997         2020.0  1.930537e+09   2020-02-19  2020-03-05   \n49998         2019.0  1.930199e+09   2019-11-27  2019-12-12   \n49999         2019.0  1.928576e+09   2019-01-05  2019-01-24   \n\n      baseline_create_date cust_payment_terms  converted_usd   Delay  \\\n0               2020-01-26               NAH4       54273.28  1 days   \n1               2019-07-22               NAD1       79656.60 -3 days   \n2               2019-09-14               NAA8        2253.86 92 days   \n3               2020-03-31               CA10        2309.79     NaT   \n4               2019-11-13               NAH4       33133.29 -3 days   \n...                    ...                ...            ...     ...   \n49995           2020-04-21               NAA8        3187.86     NaT   \n49996           2019-08-15               NAH4        6766.54  4 days   \n49997           2020-02-19               NAA8        6120.86  0 days   \n49998           2019-11-27               NAA8          63.48  0 days   \n49999           2019-01-01               NAM4        1790.30 -9 days   \n\n                         avgdelay  \n0     -3 days +07:08:49.779837776  \n1                19 days 00:00:00  \n2       8 days 02:10:54.545454545  \n3       2 days 19:03:31.764705882  \n4     -3 days +19:33:27.692307693  \n...                           ...  \n49995 -1 days +17:08:34.285714286  \n49996 -3 days +12:40:08.540925267  \n49997   1 days 01:08:34.285714285  \n49998   1 days 13:36:42.985074626  \n49999 -4 days +02:20:52.173913044  \n\n[48839 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n      <th>Delay</th>\n      <th>avgdelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020-02-11</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-01-26</td>\n      <td>NAH4</td>\n      <td>54273.28</td>\n      <td>1 days</td>\n      <td>-3 days +07:08:49.779837776</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019-08-08</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-07-22</td>\n      <td>NAD1</td>\n      <td>79656.60</td>\n      <td>-3 days</td>\n      <td>19 days 00:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019-12-30</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-09-14</td>\n      <td>NAA8</td>\n      <td>2253.86</td>\n      <td>92 days</td>\n      <td>8 days 02:10:54.545454545</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>2020-04-10</td>\n      <td>2020-03-31</td>\n      <td>CA10</td>\n      <td>2309.79</td>\n      <td>NaT</td>\n      <td>2 days 19:03:31.764705882</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019-11-25</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAH4</td>\n      <td>33133.29</td>\n      <td>-3 days</td>\n      <td>-3 days +19:33:27.692307693</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>U001</td>\n      <td>0200561861</td>\n      <td>CO corporation</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930797e+09</td>\n      <td>2020-04-21</td>\n      <td>2020-05-06</td>\n      <td>2020-04-21</td>\n      <td>NAA8</td>\n      <td>3187.86</td>\n      <td>NaT</td>\n      <td>-1 days +17:08:34.285714286</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR co</td>\n      <td>2019-09-03</td>\n      <td>2019.0</td>\n      <td>1.929744e+09</td>\n      <td>2019-08-15</td>\n      <td>2019-08-30</td>\n      <td>2019-08-15</td>\n      <td>NAH4</td>\n      <td>6766.54</td>\n      <td>4 days</td>\n      <td>-3 days +12:40:08.540925267</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>U001</td>\n      <td>0200772595</td>\n      <td>SAFEW associates</td>\n      <td>2020-03-05</td>\n      <td>2020.0</td>\n      <td>1.930537e+09</td>\n      <td>2020-02-19</td>\n      <td>2020-03-05</td>\n      <td>2020-02-19</td>\n      <td>NAA8</td>\n      <td>6120.86</td>\n      <td>0 days</td>\n      <td>1 days 01:08:34.285714285</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>U001</td>\n      <td>0200726979</td>\n      <td>BJ'S  llc</td>\n      <td>2019-12-12</td>\n      <td>2019.0</td>\n      <td>1.930199e+09</td>\n      <td>2019-11-27</td>\n      <td>2019-12-12</td>\n      <td>2019-11-27</td>\n      <td>NAA8</td>\n      <td>63.48</td>\n      <td>0 days</td>\n      <td>1 days 13:36:42.985074626</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>U001</td>\n      <td>0200020431</td>\n      <td>DEC corp</td>\n      <td>2019-01-15</td>\n      <td>2019.0</td>\n      <td>1.928576e+09</td>\n      <td>2019-01-05</td>\n      <td>2019-01-24</td>\n      <td>2019-01-01</td>\n      <td>NAM4</td>\n      <td>1790.30</td>\n      <td>-9 days</td>\n      <td>-4 days +02:20:52.173913044</td>\n    </tr>\n  </tbody>\n</table>\n<p>48839 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d332525",
   "metadata": {
    "id": "1d332525"
   },
   "source": [
    "### Observe that the \"avg_delay\" column is in days format. You need to change the format into seconds\n",
    "\n",
    "- Days_format :  17 days 00:00:00\n",
    "- Format in seconds : 1641600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d5f1041e",
   "metadata": {
    "id": "d5f1041e"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [134]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavgdelay\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mavgdelay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdt\u001B[49m\u001B[38;5;241m.\u001B[39mtotal_seconds()\n\u001B[0;32m      3\u001B[0m df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavgdelay\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5577\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5578\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5579\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5580\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5581\u001B[0m ):\n\u001B[0;32m   5582\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5583\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001B[0m, in \u001B[0;36mCachedAccessor.__get__\u001B[1;34m(self, obj, cls)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001B[39;00m\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessor\n\u001B[1;32m--> 182\u001B[0m accessor_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;66;03m# NDFrame\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name, accessor_obj)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:509\u001B[0m, in \u001B[0;36mCombinedDatetimelikeProperties.__new__\u001B[1;34m(cls, data)\u001B[0m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_period_dtype(data\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PeriodProperties(data, orig)\n\u001B[1;32m--> 509\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan only use .dt accessor with datetimelike values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "df[\"avgdelay\"] = df[\"avgdelay\"].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvgtHSsx_O-n",
   "metadata": {
    "id": "OvgtHSsx_O-n"
   },
   "source": [
    "### Display the maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "97ca9c45",
   "metadata": {
    "id": "97ca9c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number       name_customer  clear_date  \\\n0              U001  0200769623        WAL-MAR corp  2020-02-11   \n1              U001  0200980828              BEN E   2019-08-08   \n2              U001  0200792734          MDV/ trust  2019-12-30   \n3              CA02  0140105686            SYSC llc         NaT   \n4              U001  0200769623  WAL-MAR foundation  2019-11-25   \n...             ...         ...                 ...         ...   \n49995          U001  0200561861      CO corporation         NaT   \n49996          U001  0200769623          WAL-MAR co  2019-09-03   \n49997          U001  0200772595    SAFEW associates  2020-03-05   \n49998          U001  0200726979           BJ'S  llc  2019-12-12   \n49999          U001  0200020431            DEC corp  2019-01-15   \n\n       buisness_year        doc_id posting_date due_in_date  \\\n0             2020.0  1.930438e+09   2020-01-26  2020-02-10   \n1             2019.0  1.929646e+09   2019-07-22  2019-08-11   \n2             2019.0  1.929874e+09   2019-09-14  2019-09-29   \n3             2020.0  2.960623e+09   2020-03-30  2020-04-10   \n4             2019.0  1.930148e+09   2019-11-13  2019-11-28   \n...              ...           ...          ...         ...   \n49995         2020.0  1.930797e+09   2020-04-21  2020-05-06   \n49996         2019.0  1.929744e+09   2019-08-15  2019-08-30   \n49997         2020.0  1.930537e+09   2020-02-19  2020-03-05   \n49998         2019.0  1.930199e+09   2019-11-27  2019-12-12   \n49999         2019.0  1.928576e+09   2019-01-05  2019-01-24   \n\n      baseline_create_date cust_payment_terms  converted_usd   Delay  \\\n0               2020-01-26               NAH4       54273.28  1 days   \n1               2019-07-22               NAD1       79656.60 -3 days   \n2               2019-09-14               NAA8        2253.86 92 days   \n3               2020-03-31               CA10        2309.79     NaT   \n4               2019-11-13               NAH4       33133.29 -3 days   \n...                    ...                ...            ...     ...   \n49995           2020-04-21               NAA8        3187.86     NaT   \n49996           2019-08-15               NAH4        6766.54  4 days   \n49997           2020-02-19               NAA8        6120.86  0 days   \n49998           2019-11-27               NAA8          63.48  0 days   \n49999           2019-01-01               NAM4        1790.30 -9 days   \n\n           avgdelay  \n0     -2.334702e+05  \n1      1.641600e+06  \n2      6.990545e+05  \n3      2.414118e+05  \n4     -1.887923e+05  \n...             ...  \n49995 -2.468571e+04  \n49996 -2.135915e+05  \n49997  9.051429e+04  \n49998  1.354030e+05  \n49999 -3.371478e+05  \n\n[48839 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>clear_date</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n      <th>Delay</th>\n      <th>avgdelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020-02-11</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-01-26</td>\n      <td>NAH4</td>\n      <td>54273.28</td>\n      <td>1 days</td>\n      <td>-2.334702e+05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019-08-08</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-07-22</td>\n      <td>NAD1</td>\n      <td>79656.60</td>\n      <td>-3 days</td>\n      <td>1.641600e+06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019-12-30</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-09-14</td>\n      <td>NAA8</td>\n      <td>2253.86</td>\n      <td>92 days</td>\n      <td>6.990545e+05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>2020-04-10</td>\n      <td>2020-03-31</td>\n      <td>CA10</td>\n      <td>2309.79</td>\n      <td>NaT</td>\n      <td>2.414118e+05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019-11-25</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAH4</td>\n      <td>33133.29</td>\n      <td>-3 days</td>\n      <td>-1.887923e+05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>U001</td>\n      <td>0200561861</td>\n      <td>CO corporation</td>\n      <td>NaT</td>\n      <td>2020.0</td>\n      <td>1.930797e+09</td>\n      <td>2020-04-21</td>\n      <td>2020-05-06</td>\n      <td>2020-04-21</td>\n      <td>NAA8</td>\n      <td>3187.86</td>\n      <td>NaT</td>\n      <td>-2.468571e+04</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR co</td>\n      <td>2019-09-03</td>\n      <td>2019.0</td>\n      <td>1.929744e+09</td>\n      <td>2019-08-15</td>\n      <td>2019-08-30</td>\n      <td>2019-08-15</td>\n      <td>NAH4</td>\n      <td>6766.54</td>\n      <td>4 days</td>\n      <td>-2.135915e+05</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>U001</td>\n      <td>0200772595</td>\n      <td>SAFEW associates</td>\n      <td>2020-03-05</td>\n      <td>2020.0</td>\n      <td>1.930537e+09</td>\n      <td>2020-02-19</td>\n      <td>2020-03-05</td>\n      <td>2020-02-19</td>\n      <td>NAA8</td>\n      <td>6120.86</td>\n      <td>0 days</td>\n      <td>9.051429e+04</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>U001</td>\n      <td>0200726979</td>\n      <td>BJ'S  llc</td>\n      <td>2019-12-12</td>\n      <td>2019.0</td>\n      <td>1.930199e+09</td>\n      <td>2019-11-27</td>\n      <td>2019-12-12</td>\n      <td>2019-11-27</td>\n      <td>NAA8</td>\n      <td>63.48</td>\n      <td>0 days</td>\n      <td>1.354030e+05</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>U001</td>\n      <td>0200020431</td>\n      <td>DEC corp</td>\n      <td>2019-01-15</td>\n      <td>2019.0</td>\n      <td>1.928576e+09</td>\n      <td>2019-01-05</td>\n      <td>2019-01-24</td>\n      <td>2019-01-01</td>\n      <td>NAM4</td>\n      <td>1790.30</td>\n      <td>-9 days</td>\n      <td>-3.371478e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>48839 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24c7bb",
   "metadata": {
    "id": "ae24c7bb"
   },
   "source": [
    "### Since you have created the \"avg_delay\" column from \"Delay\" and \"clear_date\" column, there is no need of these two columns anymore \n",
    "\n",
    "- You are expected to drop \"Delay\" and \"clear_date\" columns from maindata dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "78a61ab9",
   "metadata": {
    "id": "78a61ab9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number       name_customer  buisness_year  \\\n0              U001  0200769623        WAL-MAR corp         2020.0   \n1              U001  0200980828              BEN E          2019.0   \n2              U001  0200792734          MDV/ trust         2019.0   \n3              CA02  0140105686            SYSC llc         2020.0   \n4              U001  0200769623  WAL-MAR foundation         2019.0   \n...             ...         ...                 ...            ...   \n49995          U001  0200561861      CO corporation         2020.0   \n49996          U001  0200769623          WAL-MAR co         2019.0   \n49997          U001  0200772595    SAFEW associates         2020.0   \n49998          U001  0200726979           BJ'S  llc         2019.0   \n49999          U001  0200020431            DEC corp         2019.0   \n\n             doc_id posting_date due_in_date baseline_create_date  \\\n0      1.930438e+09   2020-01-26  2020-02-10           2020-01-26   \n1      1.929646e+09   2019-07-22  2019-08-11           2019-07-22   \n2      1.929874e+09   2019-09-14  2019-09-29           2019-09-14   \n3      2.960623e+09   2020-03-30  2020-04-10           2020-03-31   \n4      1.930148e+09   2019-11-13  2019-11-28           2019-11-13   \n...             ...          ...         ...                  ...   \n49995  1.930797e+09   2020-04-21  2020-05-06           2020-04-21   \n49996  1.929744e+09   2019-08-15  2019-08-30           2019-08-15   \n49997  1.930537e+09   2020-02-19  2020-03-05           2020-02-19   \n49998  1.930199e+09   2019-11-27  2019-12-12           2019-11-27   \n49999  1.928576e+09   2019-01-05  2019-01-24           2019-01-01   \n\n      cust_payment_terms  converted_usd      avgdelay  \n0                   NAH4       54273.28 -2.334702e+05  \n1                   NAD1       79656.60  1.641600e+06  \n2                   NAA8        2253.86  6.990545e+05  \n3                   CA10        2309.79  2.414118e+05  \n4                   NAH4       33133.29 -1.887923e+05  \n...                  ...            ...           ...  \n49995               NAA8        3187.86 -2.468571e+04  \n49996               NAH4        6766.54 -2.135915e+05  \n49997               NAA8        6120.86  9.051429e+04  \n49998               NAA8          63.48  1.354030e+05  \n49999               NAM4        1790.30 -3.371478e+05  \n\n[48839 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n      <th>avgdelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2020.0</td>\n      <td>1.930438e+09</td>\n      <td>2020-01-26</td>\n      <td>2020-02-10</td>\n      <td>2020-01-26</td>\n      <td>NAH4</td>\n      <td>54273.28</td>\n      <td>-2.334702e+05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U001</td>\n      <td>0200980828</td>\n      <td>BEN E</td>\n      <td>2019.0</td>\n      <td>1.929646e+09</td>\n      <td>2019-07-22</td>\n      <td>2019-08-11</td>\n      <td>2019-07-22</td>\n      <td>NAD1</td>\n      <td>79656.60</td>\n      <td>1.641600e+06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>U001</td>\n      <td>0200792734</td>\n      <td>MDV/ trust</td>\n      <td>2019.0</td>\n      <td>1.929874e+09</td>\n      <td>2019-09-14</td>\n      <td>2019-09-29</td>\n      <td>2019-09-14</td>\n      <td>NAA8</td>\n      <td>2253.86</td>\n      <td>6.990545e+05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CA02</td>\n      <td>0140105686</td>\n      <td>SYSC llc</td>\n      <td>2020.0</td>\n      <td>2.960623e+09</td>\n      <td>2020-03-30</td>\n      <td>2020-04-10</td>\n      <td>2020-03-31</td>\n      <td>CA10</td>\n      <td>2309.79</td>\n      <td>2.414118e+05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR foundation</td>\n      <td>2019.0</td>\n      <td>1.930148e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAH4</td>\n      <td>33133.29</td>\n      <td>-1.887923e+05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>U001</td>\n      <td>0200561861</td>\n      <td>CO corporation</td>\n      <td>2020.0</td>\n      <td>1.930797e+09</td>\n      <td>2020-04-21</td>\n      <td>2020-05-06</td>\n      <td>2020-04-21</td>\n      <td>NAA8</td>\n      <td>3187.86</td>\n      <td>-2.468571e+04</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR co</td>\n      <td>2019.0</td>\n      <td>1.929744e+09</td>\n      <td>2019-08-15</td>\n      <td>2019-08-30</td>\n      <td>2019-08-15</td>\n      <td>NAH4</td>\n      <td>6766.54</td>\n      <td>-2.135915e+05</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>U001</td>\n      <td>0200772595</td>\n      <td>SAFEW associates</td>\n      <td>2020.0</td>\n      <td>1.930537e+09</td>\n      <td>2020-02-19</td>\n      <td>2020-03-05</td>\n      <td>2020-02-19</td>\n      <td>NAA8</td>\n      <td>6120.86</td>\n      <td>9.051429e+04</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>U001</td>\n      <td>0200726979</td>\n      <td>BJ'S  llc</td>\n      <td>2019.0</td>\n      <td>1.930199e+09</td>\n      <td>2019-11-27</td>\n      <td>2019-12-12</td>\n      <td>2019-11-27</td>\n      <td>NAA8</td>\n      <td>63.48</td>\n      <td>1.354030e+05</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>U001</td>\n      <td>0200020431</td>\n      <td>DEC corp</td>\n      <td>2019.0</td>\n      <td>1.928576e+09</td>\n      <td>2019-01-05</td>\n      <td>2019-01-24</td>\n      <td>2019-01-01</td>\n      <td>NAM4</td>\n      <td>1790.30</td>\n      <td>-3.371478e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>48839 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"Delay\", \"clear_date\"], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae724bfc",
   "metadata": {
    "id": "ae724bfc"
   },
   "source": [
    "# Splitting of Train and the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f0264",
   "metadata": {
    "id": "cb6f0264"
   },
   "source": [
    "### You need to split the \"maindata\" columns into X and y dataframe\n",
    "\n",
    "- Note - y should have the target column i.e. \"avg_delay\" and the other column should be in X\n",
    "\n",
    "- X is going to hold the source fields and y will be going to hold the target fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "75ab29ab",
   "metadata": {
    "id": "75ab29ab"
   },
   "outputs": [],
   "source": [
    "X_train, X_loc_test, y_train, y_local_test = train_test_split(df, df[\"avgdelay\"],train_size=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6412c62b",
   "metadata": {
    "id": "6412c62b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      business_code cust_number        name_customer  buisness_year  \\\n15799          U001      CCU013  KRAFT F corporation         2020.0   \n18561          U001  0200719839         ASSOCI trust         2019.0   \n27734          U001  0200229974  DARDEN D foundation         2019.0   \n33557          U001  0200769623         WAL-MAR corp         2019.0   \n19795          U001  0200794332         COST systems         2019.0   \n...             ...         ...                  ...            ...   \n31595          U001  0200772670        ASSOCIAT corp         2019.0   \n28872          U001  0200743129       BROOKS systems         2019.0   \n37822          U001  0200943275                 US           2019.0   \n43115          U001  0100026939      SYSC associates         2020.0   \n37538          U001  0200769623  WAL-MAR corporation         2019.0   \n\n             doc_id posting_date due_in_date baseline_create_date  \\\n15799  1.930686e+09   2020-03-26  2020-03-26           2020-03-26   \n18561  1.930145e+09   2019-11-13  2019-11-28           2019-11-13   \n27734  1.929290e+09   2019-05-10  2019-05-25           2019-05-10   \n33557  1.930216e+09   2019-12-05  2019-12-20           2019-12-05   \n19795  1.929076e+09   2019-04-04  2019-04-19           2019-04-04   \n...             ...          ...         ...                  ...   \n31595  1.929676e+09   2019-07-29  2019-08-13           2019-07-29   \n28872  1.929196e+09   2019-04-24  2019-05-09           2019-04-24   \n37822  1.929038e+09   2019-03-27  2019-04-11           2019-03-27   \n43115  1.930432e+09   2020-01-23  2020-02-07           2020-01-23   \n37538  1.930139e+09   2019-11-14  2019-11-29           2019-11-14   \n\n      cust_payment_terms  converted_usd      avgdelay  \n15799               NAX2       13294.86  3.578880e+06  \n18561               NAA8      112016.81  3.456000e+05  \n27734               NAA8       15209.57  4.752000e+05  \n33557               NAH4       11181.19 -2.334702e+05  \n19795               NAAX       36033.03 -5.540870e+04  \n...                  ...            ...           ...  \n31595               NAU5       30712.64  9.437538e+04  \n28872               NAA8       11398.13  7.560000e+04  \n37822               NAA8       25650.30  1.687814e+05  \n43115               NAA8        2505.47  4.661053e+05  \n37538               NAH4         593.97 -2.189466e+05  \n\n[29303 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_code</th>\n      <th>cust_number</th>\n      <th>name_customer</th>\n      <th>buisness_year</th>\n      <th>doc_id</th>\n      <th>posting_date</th>\n      <th>due_in_date</th>\n      <th>baseline_create_date</th>\n      <th>cust_payment_terms</th>\n      <th>converted_usd</th>\n      <th>avgdelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15799</th>\n      <td>U001</td>\n      <td>CCU013</td>\n      <td>KRAFT F corporation</td>\n      <td>2020.0</td>\n      <td>1.930686e+09</td>\n      <td>2020-03-26</td>\n      <td>2020-03-26</td>\n      <td>2020-03-26</td>\n      <td>NAX2</td>\n      <td>13294.86</td>\n      <td>3.578880e+06</td>\n    </tr>\n    <tr>\n      <th>18561</th>\n      <td>U001</td>\n      <td>0200719839</td>\n      <td>ASSOCI trust</td>\n      <td>2019.0</td>\n      <td>1.930145e+09</td>\n      <td>2019-11-13</td>\n      <td>2019-11-28</td>\n      <td>2019-11-13</td>\n      <td>NAA8</td>\n      <td>112016.81</td>\n      <td>3.456000e+05</td>\n    </tr>\n    <tr>\n      <th>27734</th>\n      <td>U001</td>\n      <td>0200229974</td>\n      <td>DARDEN D foundation</td>\n      <td>2019.0</td>\n      <td>1.929290e+09</td>\n      <td>2019-05-10</td>\n      <td>2019-05-25</td>\n      <td>2019-05-10</td>\n      <td>NAA8</td>\n      <td>15209.57</td>\n      <td>4.752000e+05</td>\n    </tr>\n    <tr>\n      <th>33557</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corp</td>\n      <td>2019.0</td>\n      <td>1.930216e+09</td>\n      <td>2019-12-05</td>\n      <td>2019-12-20</td>\n      <td>2019-12-05</td>\n      <td>NAH4</td>\n      <td>11181.19</td>\n      <td>-2.334702e+05</td>\n    </tr>\n    <tr>\n      <th>19795</th>\n      <td>U001</td>\n      <td>0200794332</td>\n      <td>COST systems</td>\n      <td>2019.0</td>\n      <td>1.929076e+09</td>\n      <td>2019-04-04</td>\n      <td>2019-04-19</td>\n      <td>2019-04-04</td>\n      <td>NAAX</td>\n      <td>36033.03</td>\n      <td>-5.540870e+04</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31595</th>\n      <td>U001</td>\n      <td>0200772670</td>\n      <td>ASSOCIAT corp</td>\n      <td>2019.0</td>\n      <td>1.929676e+09</td>\n      <td>2019-07-29</td>\n      <td>2019-08-13</td>\n      <td>2019-07-29</td>\n      <td>NAU5</td>\n      <td>30712.64</td>\n      <td>9.437538e+04</td>\n    </tr>\n    <tr>\n      <th>28872</th>\n      <td>U001</td>\n      <td>0200743129</td>\n      <td>BROOKS systems</td>\n      <td>2019.0</td>\n      <td>1.929196e+09</td>\n      <td>2019-04-24</td>\n      <td>2019-05-09</td>\n      <td>2019-04-24</td>\n      <td>NAA8</td>\n      <td>11398.13</td>\n      <td>7.560000e+04</td>\n    </tr>\n    <tr>\n      <th>37822</th>\n      <td>U001</td>\n      <td>0200943275</td>\n      <td>US</td>\n      <td>2019.0</td>\n      <td>1.929038e+09</td>\n      <td>2019-03-27</td>\n      <td>2019-04-11</td>\n      <td>2019-03-27</td>\n      <td>NAA8</td>\n      <td>25650.30</td>\n      <td>1.687814e+05</td>\n    </tr>\n    <tr>\n      <th>43115</th>\n      <td>U001</td>\n      <td>0100026939</td>\n      <td>SYSC associates</td>\n      <td>2020.0</td>\n      <td>1.930432e+09</td>\n      <td>2020-01-23</td>\n      <td>2020-02-07</td>\n      <td>2020-01-23</td>\n      <td>NAA8</td>\n      <td>2505.47</td>\n      <td>4.661053e+05</td>\n    </tr>\n    <tr>\n      <th>37538</th>\n      <td>U001</td>\n      <td>0200769623</td>\n      <td>WAL-MAR corporation</td>\n      <td>2019.0</td>\n      <td>1.930139e+09</td>\n      <td>2019-11-14</td>\n      <td>2019-11-29</td>\n      <td>2019-11-14</td>\n      <td>NAH4</td>\n      <td>593.97</td>\n      <td>-2.189466e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>29303 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### You are expected to split both the dataframes into train and test format in 60:40 ratio\n",
    "\n",
    "- Note - The expected output should be in \"X_train\", \"X_loc_test\", \"y_train\", \"y_loc_test\" format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "p4OME62pDufR",
   "metadata": {
    "id": "p4OME62pDufR"
   },
   "source": [
    "### Please check for the number of rows and columns of all the new dataframes (all 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "48328d0a",
   "metadata": {
    "id": "48328d0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((29303, 11), (19536, 11), (29303,), (19536,))"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_loc_test.shape, y_train.shape, y_local_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68ed71",
   "metadata": {
    "id": "4a68ed71"
   },
   "source": [
    "### Now you are expected to split the \"X_loc_test\" and \"y_loc_test\" dataset into \"Test\" and \"Validation\" (as the names given below) dataframe with 50:50 format \n",
    "\n",
    "- Note - The expected output should be in \"X_val\", \"X_test\", \"y_val\", \"y_test\" format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b56c62f2",
   "metadata": {
    "id": "b56c62f2"
   },
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_loc_test, y_local_test, train_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJTSAskvERH1",
   "metadata": {
    "id": "bJTSAskvERH1"
   },
   "source": [
    "### Please check for the number of rows and columns of all the 4 dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "845d7564",
   "metadata": {
    "id": "845d7564"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((9768, 11), (9768, 11), (9768,), (9768,))"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, X_test.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fa872",
   "metadata": {
    "id": "110fa872"
   },
   "source": [
    "# Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8fe0f",
   "metadata": {
    "id": "ffc8fe0f"
   },
   "source": [
    "### Distribution Plot of the target variable (use the dataframe which contains the target field)\n",
    "\n",
    "- Note - You are expected to make a distribution plot for the target variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bf8ed",
   "metadata": {
    "id": "ba2bf8ed"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e323a3",
   "metadata": {
    "id": "d0e323a3"
   },
   "source": [
    "### You are expected to group the X_train dataset on 'name_customer' column with 'doc_id' in the x_train set\n",
    "\n",
    "### Need to store the outcome into a new dataframe \n",
    "\n",
    "- Note code given for groupby statement- X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0ee",
   "metadata": {
    "id": "f7acf0ee"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cA43bFffFt6i",
   "metadata": {
    "id": "cA43bFffFt6i"
   },
   "source": [
    "### You can make another distribution plot of the \"doc_id\" column from x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576bf33",
   "metadata": {
    "id": "9576bf33"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fba2c44f",
   "metadata": {
    "id": "fba2c44f"
   },
   "source": [
    "#### Create a Distribution plot only for business_year and a seperate distribution plot of \"business_year\" column along with the doc_id\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecec77",
   "metadata": {
    "id": "4fecec77"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qr1jGhfOKjnw",
   "metadata": {
    "id": "qr1jGhfOKjnw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "968fbcc9",
   "metadata": {
    "id": "968fbcc9"
   },
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jbh6CyGqH3XE",
   "metadata": {
    "id": "jbh6CyGqH3XE"
   },
   "source": [
    "### Display and describe the X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcf307",
   "metadata": {
    "id": "e6bcf307"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc819",
   "metadata": {
    "id": "08ccc819"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd7ac8b",
   "metadata": {
    "id": "abd7ac8b"
   },
   "source": [
    "#### The \"business_code\" column inside X_train, is a categorical column, so you need to perform Labelencoder on that particular column\n",
    "\n",
    "- Note - call the Label Encoder from sklearn library and use the fit() function on \"business_code\" column\n",
    "- Note - Please fill in the blanks (two) to complete this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c223545",
   "metadata": {
    "id": "7c223545"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "business_coder = LabelEncoder()\n",
    "business_coder.___(X_train[__________])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f7d9c",
   "metadata": {
    "id": "f86f7d9c"
   },
   "source": [
    "#### You are expected to store the value into a new column i.e. \"business_code_enc\"\n",
    "\n",
    "- Note - For Training set you are expected to use fit_trainsform()\n",
    "- Note - For Test set you are expected to use the trainsform()\n",
    "- Note - For Validation set you are expected to use the trainsform()\n",
    "\n",
    "\n",
    "- Partial code is provided, please fill in the blanks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269c307",
   "metadata": {
    "id": "4269c307"
   },
   "outputs": [],
   "source": [
    "X_train[\"business_code_enc\"] = business_coder._____________(\n",
    "    X_train[\"business_code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53712",
   "metadata": {
    "id": "70a53712"
   },
   "outputs": [],
   "source": [
    "X_val[\"business_code_enc\"] = business_coder.__________(X_val[\"business_code\"])\n",
    "X_test[\"business_code_enc\"] = business_coder.____________(\n",
    "    X_test[\"business_code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gdNYxTkqNfmz",
   "metadata": {
    "id": "gdNYxTkqNfmz"
   },
   "source": [
    "### Display \"business_code\" and \"business_code_enc\" together from X_train dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196a002",
   "metadata": {
    "id": "1196a002"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11477224",
   "metadata": {
    "id": "11477224"
   },
   "source": [
    "#### Create a function called \"custom\" for dropping the columns 'business_code' from train, test and validation dataframe\n",
    "\n",
    "- Note - Fill in the blank to complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052868a",
   "metadata": {
    "id": "1052868a"
   },
   "outputs": [],
   "source": [
    "def ________(col, traindf=X_train, valdf=X_val, testdf=X_test):\n",
    "    traindf.drop(col, axis=1, inplace=True)\n",
    "    valdf.drop(col, axis=1, inplace=True)\n",
    "    testdf.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    return traindf, valdf, testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rI--ZuMbNLne",
   "metadata": {
    "id": "rI--ZuMbNLne"
   },
   "source": [
    "### Call the function by passing the column name which needed to be dropped from train, test and validation dataframes. Return updated dataframes to be stored in X_train ,X_val, X_test  \n",
    "\n",
    "- Note = Fill in the blank to complete the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f955c",
   "metadata": {
    "id": "1a0f955c"
   },
   "outputs": [],
   "source": [
    "________, ______, _______ = ______([\"business_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5b27e",
   "metadata": {
    "id": "28b5b27e"
   },
   "source": [
    "### Manually replacing str values with numbers, Here we are trying manually replace the customer numbers with some specific values like, 'CCCA' as 1, 'CCU' as 2 and so on. Also we are converting the datatype \"cust_number\" field to int type.\n",
    "\n",
    "- We are doing it for all the three dataframes as shown below. This is fully completed code. No need to modify anything here \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd129e",
   "metadata": {
    "id": "85dd129e"
   },
   "outputs": [],
   "source": [
    "X_train[\"cust_number\"] = (\n",
    "    X_train[\"cust_number\"]\n",
    "        .str.replace(\"CCCA\", \"1\")\n",
    "        .str.replace(\"CCU\", \"2\")\n",
    "        .str.replace(\"CC\", \"3\")\n",
    "        .astype(int)\n",
    ")\n",
    "X_test[\"cust_number\"] = (\n",
    "    X_test[\"cust_number\"]\n",
    "        .str.replace(\"CCCA\", \"1\")\n",
    "        .str.replace(\"CCU\", \"2\")\n",
    "        .str.replace(\"CC\", \"3\")\n",
    "        .astype(int)\n",
    ")\n",
    "X_val[\"cust_number\"] = (\n",
    "    X_val[\"cust_number\"]\n",
    "        .str.replace(\"CCCA\", \"1\")\n",
    "        .str.replace(\"CCU\", \"2\")\n",
    "        .str.replace(\"CC\", \"3\")\n",
    "        .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U8vA-zmdPnJ8",
   "metadata": {
    "id": "U8vA-zmdPnJ8"
   },
   "source": [
    "#### It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]. Unknown will be added in fit and transform will take care of new item. It gives unknown class id.\n",
    "\n",
    "#### This will fit the encoder for all the unique values and introduce unknown value\n",
    "\n",
    "- Note - Keep this code as it is, we will be using this later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f48ba",
   "metadata": {
    "id": "151f48ba"
   },
   "outputs": [],
   "source": [
    "# For encoding unseen labels\n",
    "class EncoderExt(object):\n",
    "    def __init__(self):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        self.label_encoder = self.label_encoder.fit(\n",
    "            list(data_list) + [\"Unknown\"]\n",
    "        )\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = [\n",
    "                    \"Unknown\" if x == unique_item else x for x in new_data_list\n",
    "                ]\n",
    "        return self.label_encoder.transform(new_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c64e6",
   "metadata": {
    "id": "254c64e6"
   },
   "source": [
    "### Use the user define Label Encoder function called \"EncoderExt\" for the \"name_customer\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b17eff",
   "metadata": {
    "id": "62b17eff"
   },
   "outputs": [],
   "source": [
    "label_encoder = EncoderExt()\n",
    "label_encoder.fit(X_train[\"name_customer\"])\n",
    "X_train[\"name_customer_enc\"] = label_encoder.transform(X_train[\"name_customer\"])\n",
    "X_val[\"name_customer_enc\"] = label_encoder.transform(X_val[\"name_customer\"])\n",
    "X_test[\"name_customer_enc\"] = label_encoder.transform(X_test[\"name_customer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mK7LMoy2QZhy",
   "metadata": {
    "id": "mK7LMoy2QZhy"
   },
   "source": [
    "### As we have created the a new column \"name_customer_enc\", so now drop \"name_customer\" column from all three dataframes\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85f1c0",
   "metadata": {
    "id": "ef85f1c0"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = custom([\"name_customer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa09d22",
   "metadata": {
    "id": "3aa09d22"
   },
   "source": [
    "### Using Label Encoder for the \"cust_payment_terms\" column\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ab642",
   "metadata": {
    "id": "6f9ab642"
   },
   "outputs": [],
   "source": [
    "label_encoder1 = EncoderExt()\n",
    "label_encoder1.fit(X_train[\"cust_payment_terms\"])\n",
    "X_train[\"cust_payment_terms_enc\"] = label_encoder1.transform(\n",
    "    X_train[\"cust_payment_terms\"]\n",
    ")\n",
    "X_val[\"cust_payment_terms_enc\"] = label_encoder1.transform(\n",
    "    X_val[\"cust_payment_terms\"]\n",
    ")\n",
    "X_test[\"cust_payment_terms_enc\"] = label_encoder1.transform(\n",
    "    X_test[\"cust_payment_terms\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f9a7c2",
   "metadata": {
    "id": "55f9a7c2"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = custom([\"cust_payment_terms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788f42b",
   "metadata": {
    "id": "0788f42b"
   },
   "source": [
    "## Check the datatype of all the columns of Train, Test and Validation dataframes realted to X\n",
    "\n",
    "- Note - You are expected yo use dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79a316",
   "metadata": {
    "id": "bc79a316"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33242d8",
   "metadata": {
    "id": "b33242d8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4da71",
   "metadata": {
    "id": "6bd4da71"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "LVfvuPiWPeMB",
   "metadata": {
    "id": "LVfvuPiWPeMB"
   },
   "source": [
    "### From the above output you can notice their are multiple date columns with datetime format\n",
    "\n",
    "### In order to pass it into our model, we need to convert it into float format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d344db9",
   "metadata": {
    "id": "9d344db9"
   },
   "source": [
    "### You need to extract day, month and year from the \"posting_date\" column \n",
    "\n",
    "1.   Extract days from \"posting_date\" column and store it into a new column \"day_of_postingdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"posting_date\" column and store it into a new column \"month_of_postingdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"posting_date\" column and store it into a new column \"year_of_postingdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3cdfd6",
   "metadata": {
    "id": "6e3cdfd6"
   },
   "outputs": [],
   "source": [
    "X_train[\"day_of_postingdate\"] = X_train[\"posting_date\"].dt.day\n",
    "X_train[\"month_of_postingdate\"] = X_train[\"posting_date\"].dt.month\n",
    "X_train[\"year_of_postingdate\"] = X_train[\"posting_date\"].dt.year\n",
    "\n",
    "X_val[\"day_of_postingdate\"] = X_val[\"posting_date\"].dt.day\n",
    "X_val[\"month_of_postingdate\"] = X_val[\"posting_date\"].dt.month\n",
    "X_val[\"year_of_postingdate\"] = X_val[\"posting_date\"].dt.year\n",
    "\n",
    "X_test[\"day_of_postingdate\"] = X_test[\"posting_date\"].dt.day\n",
    "X_test[\"month_of_postingdate\"] = X_test[\"posting_date\"].dt.month\n",
    "X_test[\"year_of_postingdate\"] = X_test[\"posting_date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GyI-F853Rxa7",
   "metadata": {
    "id": "GyI-F853Rxa7"
   },
   "source": [
    "### pass the \"posting_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FQHtQkrnRx_V",
   "metadata": {
    "id": "FQHtQkrnRx_V"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = custom([\"posting_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GMnCaEcKReSw",
   "metadata": {
    "id": "GMnCaEcKReSw"
   },
   "source": [
    "### You need to extract day, month and year from the \"baseline_create_date\" column \n",
    "\n",
    "1.   Extract days from \"baseline_create_date\" column and store it into a new column \"day_of_createdate\" for train, test and validation dataset \n",
    "2.   Extract months from \"baseline_create_date\" column and store it into a new column \"month_of_createdate\" for train, test and validation dataset\n",
    "3.   Extract year from \"baseline_create_date\" column and store it into a new column \"year_of_createdate\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "\n",
    "- Note - Do as it is been shown in the previous two code boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d83d0",
   "metadata": {
    "id": "ee4d83d0"
   },
   "source": [
    "### Extracting Day, Month, Year for 'baseline_create_date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b240e1",
   "metadata": {
    "id": "32b240e1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cFgwkS5rSDDs",
   "metadata": {
    "id": "cFgwkS5rSDDs"
   },
   "source": [
    "### pass the \"baseline_create_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGYa2BEQSDg3",
   "metadata": {
    "id": "RGYa2BEQSDg3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77c7a0df",
   "metadata": {
    "id": "77c7a0df"
   },
   "source": [
    "### You need to extract day, month and year from the \"due_in_date\" column \n",
    "\n",
    "1.   Extract days from \"due_in_date\" column and store it into a new column \"day_of_due\" for train, test and validation dataset \n",
    "2.   Extract months from \"due_in_date\" column and store it into a new column \"month_of_due\" for train, test and validation dataset\n",
    "3.   Extract year from \"due_in_date\" column and store it into a new column \"year_of_due\" for train, test and validation dataset \n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed yo use \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year\n",
    "\n",
    "- Note - Do as it is been shown in the previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c745547",
   "metadata": {
    "id": "5c745547"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "FYLLzulGSvRd",
   "metadata": {
    "id": "FYLLzulGSvRd"
   },
   "source": [
    "pass the \"due_in_date\" column into the Custom function for train, test and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1-s6QuY9Svrh",
   "metadata": {
    "id": "1-s6QuY9Svrh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ae5d052",
   "metadata": {
    "id": "1ae5d052"
   },
   "source": [
    "### Check for the datatypes for train, test and validation set again\n",
    "\n",
    "- Note - all the data type should be in either int64 or float64 format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9d828",
   "metadata": {
    "id": "aee9d828"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65810f55",
   "metadata": {
    "id": "65810f55"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1ad9f",
   "metadata": {
    "id": "4bb1ad9f"
   },
   "source": [
    "### Filter Method\n",
    "\n",
    "- Calling the VarianceThreshold Function \n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882509f",
   "metadata": {
    "id": "e882509f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "constant_filter.fit(X_train)\n",
    "len(X_train.columns[constant_filter.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V9531H3jR-W2",
   "metadata": {
    "id": "V9531H3jR-W2"
   },
   "source": [
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c12e1",
   "metadata": {
    "id": "c77c12e1"
   },
   "outputs": [],
   "source": [
    "constant_columns = [\n",
    "    column\n",
    "    for column in X_train.columns\n",
    "    if column not in X_train.columns[constant_filter.get_support()]\n",
    "]\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b8610",
   "metadata": {
    "id": "6d9b8610"
   },
   "source": [
    "- transpose the feature matrice\n",
    "- print the number of duplicated features\n",
    "- select the duplicated features columns names\n",
    "\n",
    "- Note - Keep the code as it is, no need to change \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7db95",
   "metadata": {
    "id": "0fb7db95"
   },
   "outputs": [],
   "source": [
    "x_train_T = X_train.T\n",
    "print(x_train_T.duplicated().sum())\n",
    "duplicated_columns = x_train_T[x_train_T.duplicated()].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fa831",
   "metadata": {
    "id": "510fa831"
   },
   "source": [
    "### Filtering depending upon correlation matrix value\n",
    "- We have created a function called handling correlation which is going to return fields based on the correlation matrix value with a threshold of 0.8\n",
    "\n",
    "- Note - Keep the code as it is, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67731abc",
   "metadata": {
    "id": "67731abc"
   },
   "outputs": [],
   "source": [
    "def handling_correlation(X_train, threshold=0.8):\n",
    "    corr_features = set()\n",
    "    corr_matrix = X_train.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_features.add(colname)\n",
    "    return list(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JaE_6qVgSXl3",
   "metadata": {
    "id": "JaE_6qVgSXl3"
   },
   "source": [
    "- Note : Here we are trying to find out the relevant fields, from X_train\n",
    "- Please fill in the blanks to call handling_correlation() function with a threshold value of 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d1a2",
   "metadata": {
    "id": "dd91d1a2"
   },
   "outputs": [],
   "source": [
    "train = X_train.copy()\n",
    "____________________(train.copy(), ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154da511",
   "metadata": {
    "id": "154da511"
   },
   "source": [
    "### Heatmap for X_train\n",
    "\n",
    "- Note - Keep the code as it is, no need to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f2fe4",
   "metadata": {
    "id": "2e8f2fe4"
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.title(\"Pearson Correlation of Features\", y=1.05, size=20)\n",
    "sns.heatmap(\n",
    "    X_train.merge(y_train, on=X_train.index).corr(),\n",
    "    linewidths=0.1,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"gist_rainbow_r\",\n",
    "    linecolor=\"white\",\n",
    "    annot=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0d745",
   "metadata": {
    "id": "e3b0d745"
   },
   "source": [
    "#### Calling variance threshold for threshold value = 0.8\n",
    "\n",
    "- Note -  Fill in the blanks to call the appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2080f",
   "metadata": {
    "id": "a9b2080f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = _________________(0.8)\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8c3dc",
   "metadata": {
    "id": "6cb8c3dc"
   },
   "outputs": [],
   "source": [
    "sel.variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62633a84",
   "metadata": {
    "id": "62633a84"
   },
   "source": [
    "### Important features columns are \n",
    "- 'year_of_createdate' \n",
    "- 'year_of_due'\n",
    "- 'day_of_createdate'\n",
    "- 'year_of_postingdate'\n",
    "- 'month_of_due'\n",
    "- 'month_of_createdate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f1ad0",
   "metadata": {
    "id": "651f1ad0"
   },
   "source": [
    "# Modelling \n",
    "\n",
    "#### Now you need to compare with different machine learning models, and needs to find out the best predicted model\n",
    "\n",
    "- Linear Regression\n",
    "- Decision Tree Regression\n",
    "- Random Forest Regression\n",
    "- Support Vector Regression\n",
    "- Extreme Gradient Boost Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PicEhSuUUOkt",
   "metadata": {
    "id": "PicEhSuUUOkt"
   },
   "source": [
    "### You need to make different blank list for different evaluation matrix \n",
    "\n",
    "- MSE\n",
    "- R2\n",
    "- Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e12b0",
   "metadata": {
    "id": "701e12b0"
   },
   "outputs": [],
   "source": [
    "MSE_Score = []\n",
    "R2_Score = []\n",
    "Algorithm = []\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29310119",
   "metadata": {
    "id": "29310119"
   },
   "source": [
    "### You need to start with the baseline model Linear Regression\n",
    "\n",
    "- Step 1 : Call the Linear Regression from sklearn library\n",
    "- Step 2 : make an object of Linear Regression \n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdea395",
   "metadata": {
    "id": "6bdea395"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Algorithm.append(\"LinearRegression\")\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G02cpnBhXJ14",
   "metadata": {
    "id": "G02cpnBhXJ14"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f69ca19",
   "metadata": {
    "id": "0f69ca19"
   },
   "outputs": [],
   "source": [
    "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
    "R2_Score.append(r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CsmScbHjYMv1",
   "metadata": {
    "id": "CsmScbHjYMv1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe653295",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe653295",
    "outputId": "0c7429ca-50d0-42a2-96a1-effaa92f549e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558507.5192899788"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = regressor.predict(X_val)\n",
    "mean_squared_error(y_val, predict_test, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LokxV2LGYUVh",
   "metadata": {
    "id": "LokxV2LGYUVh"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c405bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c405bd3",
    "outputId": "9d78f4a9-33fc-48d1-edc8-c997eca38de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LinearRegression'],[301562130566.1857],[0.31842493436013597],"
     ]
    }
   ],
   "source": [
    "for i in Algorithm, MSE_Score, R2_Score:\n",
    "    print(i, end=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e65c86",
   "metadata": {
    "id": "b0e65c86"
   },
   "source": [
    "### You need to start with the baseline model Support Vector Regression\n",
    "\n",
    "- Step 1 : Call the Support Vector Regressor from sklearn library\n",
    "- Step 2 : make an object of SVR\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5de08",
   "metadata": {
    "id": "ccb5de08"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "zz9kcrViYt7e",
   "metadata": {
    "id": "zz9kcrViYt7e"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for \"y_test\" and \"predicted\" dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9db76",
   "metadata": {
    "id": "5bb9db76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0YAxd8N9Y0hJ",
   "metadata": {
    "id": "0YAxd8N9Y0hJ"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee71b1",
   "metadata": {
    "id": "d6ee71b1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eGcqS5EcY4BI",
   "metadata": {
    "id": "eGcqS5EcY4BI"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72c1ec",
   "metadata": {
    "id": "aa72c1ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dad18bb3",
   "metadata": {
    "id": "dad18bb3"
   },
   "source": [
    "### Your next model would be Decision Tree Regression\n",
    "\n",
    "- Step 1 : Call the Decision Tree Regressor from sklearn library\n",
    "- Step 2 : make an object of Decision Tree\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a51eb",
   "metadata": {
    "id": "1b6a51eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "AOzfgfeOZo3F",
   "metadata": {
    "id": "AOzfgfeOZo3F"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e6983",
   "metadata": {
    "id": "776e6983"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eI6d49DQZrhW",
   "metadata": {
    "id": "eI6d49DQZrhW"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fb55c",
   "metadata": {
    "id": "155fb55c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sbGXvBLQZw5E",
   "metadata": {
    "id": "sbGXvBLQZw5E"
   },
   "source": [
    "### Display The Comparison Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74d515",
   "metadata": {
    "id": "1d74d515"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ae9979b",
   "metadata": {
    "id": "4ae9979b"
   },
   "source": [
    "### Your next model would be Random Forest Regression\n",
    "\n",
    "- Step 1 : Call the Random Forest Regressor from sklearn library\n",
    "- Step 2 : make an object of Random Forest\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e476a",
   "metadata": {
    "id": "a69e476a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "XNcEJF-6anof",
   "metadata": {
    "id": "XNcEJF-6anof"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f63f4",
   "metadata": {
    "id": "826f63f4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "yMbyr9V4ati1",
   "metadata": {
    "id": "yMbyr9V4ati1"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9fb54",
   "metadata": {
    "id": "55b9fb54"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tiBawcCsaw_Z",
   "metadata": {
    "id": "tiBawcCsaw_Z"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c13e",
   "metadata": {
    "id": "8277c13e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6b21881",
   "metadata": {
    "id": "e6b21881"
   },
   "source": [
    "### The last but not the least model would be XGBoost or Extreme Gradient Boost Regression\n",
    "\n",
    "- Step 1 : Call the XGBoost Regressor from xgb library\n",
    "- Step 2 : make an object of Xgboost\n",
    "- Step 3 : fit the X_train and y_train dataframe into the object \n",
    "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - Append the Algorithm name into the algorithm list for tracking purpose### Extreme Gradient Boost Regression\n",
    "- Note -  No need to change the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a38ec",
   "metadata": {
    "id": "705a38ec"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "Algorithm.append(\"XGB Regressor\")\n",
    "regressor = xgb.XGBRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ierNZkb9bQDD",
   "metadata": {
    "id": "ierNZkb9bQDD"
   },
   "source": [
    "### Check for the \n",
    "\n",
    "- Mean Square Error\n",
    "- R Square Error \n",
    "\n",
    "for y_test and predicted dataset and store those data inside respective list for comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a9d2f",
   "metadata": {
    "id": "507a9d2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84UZ2ojsbWaH",
   "metadata": {
    "id": "84UZ2ojsbWaH"
   },
   "source": [
    "### Check the same for the Validation set also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ac250",
   "metadata": {
    "id": "e78ac250"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9FJFyaVbbbAH",
   "metadata": {
    "id": "9FJFyaVbbbAH"
   },
   "source": [
    "### Display The Comparison Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765ba35",
   "metadata": {
    "id": "f765ba35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71bc90f",
   "metadata": {
    "id": "a71bc90f"
   },
   "source": [
    "## You need to make the comparison list into a comparison dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5159a7",
   "metadata": {
    "id": "ff5159a7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62e61c60",
   "metadata": {
    "id": "62e61c60"
   },
   "source": [
    "## Now from the Comparison table, you need to choose the best fit model\n",
    "\n",
    "- Step 1 - Fit X_train and y_train inside the model \n",
    "- Step 2 - Predict the X_test dataset\n",
    "- Step 3 - Predict the X_val dataset\n",
    "\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07c258",
   "metadata": {
    "id": "3e07c258"
   },
   "outputs": [],
   "source": [
    "regressorfinal = xgb.XGBRegressor()\n",
    "regressorfinal.fit(X_train, y_train)\n",
    "predictedfinal = regressorfinal.predict(X_test)\n",
    "predict_testfinal = regressorfinal.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4df6c4",
   "metadata": {
    "id": "8e4df6c4"
   },
   "source": [
    "### Calculate the Mean Square Error for test dataset\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb466d0",
   "metadata": {
    "id": "5fb466d0"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, predictedfinal, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27f87f",
   "metadata": {
    "id": "ce27f87f"
   },
   "source": [
    "### Calculate the mean Square Error for validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47978ea",
   "metadata": {
    "id": "b47978ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30014dbd",
   "metadata": {
    "id": "30014dbd"
   },
   "source": [
    "### Calculate the R2 score for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a162737",
   "metadata": {
    "id": "8a162737"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9853b0",
   "metadata": {
    "id": "1c9853b0"
   },
   "source": [
    "### Calculate the R2 score for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6dc77c",
   "metadata": {
    "id": "1a6dc77c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "499522d9",
   "metadata": {
    "id": "499522d9"
   },
   "source": [
    "### Calculate the Accuracy for train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f1ce8",
   "metadata": {
    "id": "7a4f1ce8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12a1c921",
   "metadata": {
    "id": "12a1c921"
   },
   "source": [
    "### Calculate the accuracy for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2579b4f",
   "metadata": {
    "id": "d2579b4f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79b82e84",
   "metadata": {
    "id": "79b82e84"
   },
   "source": [
    "### Calculate the accuracy for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e6431",
   "metadata": {
    "id": "f09e6431"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9488a5d9",
   "metadata": {
    "id": "9488a5d9"
   },
   "source": [
    "## Specify the reason behind choosing your machine learning model \n",
    "\n",
    "- Note : Provide your answer as a text here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a6519",
   "metadata": {
    "id": "387a6519"
   },
   "source": [
    "## Now you need to pass the Nulldata dataframe into this machine learning model\n",
    "\n",
    "#### In order to pass this Nulldata dataframe into the ML model, we need to perform the following\n",
    "\n",
    "- Step 1 : Label Encoding \n",
    "- Step 2 : Day, Month and Year extraction \n",
    "- Step 3 : Change all the column data type into int64 or float64\n",
    "- Step 4 : Need to drop the useless columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I7JuxAkdiAdI",
   "metadata": {
    "id": "I7JuxAkdiAdI"
   },
   "source": [
    "### Display the Nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a51d2",
   "metadata": {
    "id": "6d6a51d2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Vamx5xqtiHCH",
   "metadata": {
    "id": "Vamx5xqtiHCH"
   },
   "source": [
    "### Check for the number of rows and columns in the nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de1092",
   "metadata": {
    "id": "59de1092"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "BxzHNbBjpqXL",
   "metadata": {
    "id": "BxzHNbBjpqXL"
   },
   "source": [
    "### Check the Description and Information of the nulldata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294d29",
   "metadata": {
    "id": "a6294d29"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe860d94",
   "metadata": {
    "id": "fe860d94"
   },
   "source": [
    "### Storing the Nulldata into a different dataset \n",
    "# for BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16352034",
   "metadata": {
    "id": "16352034"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00f35b8c",
   "metadata": {
    "id": "00f35b8c"
   },
   "source": [
    "### Call the Label Encoder for Nulldata\n",
    "\n",
    "- Note - you are expected to fit \"business_code\" as it is a categorical variable\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf04b17",
   "metadata": {
    "id": "baf04b17"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "business_codern = LabelEncoder()\n",
    "business_codern.fit(nulldata[\"business_code\"])\n",
    "nulldata[\"business_code_enc\"] = business_codern.transform(\n",
    "    nulldata[\"business_code\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZCPBK9karIR-",
   "metadata": {
    "id": "ZCPBK9karIR-"
   },
   "source": [
    "### Now you need to manually replacing str values with numbers\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64924be",
   "metadata": {
    "id": "c64924be"
   },
   "outputs": [],
   "source": [
    "nulldata[\"cust_number\"] = (\n",
    "    nulldata[\"cust_number\"]\n",
    "        .str.replace(\"CCCA\", \"1\")\n",
    "        .str.replace(\"CCU\", \"2\")\n",
    "        .str.replace(\"CC\", \"3\")\n",
    "        .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55f5f6",
   "metadata": {
    "id": "9a55f5f6"
   },
   "source": [
    "## You need to extract day, month and year from the \"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\" columns\n",
    "\n",
    "\n",
    "##### 1.   Extract day from \"clear_date\" column and store it into 'day_of_cleardate'\n",
    "##### 2.   Extract month from \"clear_date\" column and store it into 'month_of_cleardate'\n",
    "##### 3.   Extract year from \"clear_date\" column and store it into 'year_of_cleardate'\n",
    "\n",
    "\n",
    "\n",
    "##### 4.   Extract day from \"posting_date\" column and store it into 'day_of_postingdate'\n",
    "##### 5.   Extract month from \"posting_date\" column and store it into 'month_of_postingdate'\n",
    "##### 6.   Extract year from \"posting_date\" column and store it into 'year_of_postingdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 7.   Extract day from \"due_in_date\" column and store it into 'day_of_due'\n",
    "##### 8.   Extract month from \"due_in_date\" column and store it into 'month_of_due'\n",
    "##### 9.   Extract year from \"due_in_date\" column and store it into 'year_of_due'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### 10.   Extract day from \"baseline_create_date\" column and store it into 'day_of_createdate'\n",
    "##### 11.   Extract month from \"baseline_create_date\" column and store it into 'month_of_createdate'\n",
    "##### 12.   Extract year from \"baseline_create_date\" column and store it into 'year_of_createdate'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note - You are supposed To use - \n",
    "\n",
    "*   dt.day\n",
    "*   dt.month\n",
    "*   dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166fbe4",
   "metadata": {
    "id": "4166fbe4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "QeHWJYrAvOC6",
   "metadata": {
    "id": "QeHWJYrAvOC6"
   },
   "source": [
    "### Use Label Encoder1 of all the following columns - \n",
    "- 'cust_payment_terms' and store into 'cust_payment_terms_enc'\n",
    "- 'business_code' and store into 'business_code_enc'\n",
    "- 'name_customer' and store into 'name_customer_enc'\n",
    "\n",
    "Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac330e2",
   "metadata": {
    "id": "bac330e2"
   },
   "outputs": [],
   "source": [
    "nulldata[\"cust_payment_terms_enc\"] = label_encoder1.transform(\n",
    "    nulldata[\"cust_payment_terms\"]\n",
    ")\n",
    "nulldata[\"business_code_enc\"] = label_encoder1.transform(\n",
    "    nulldata[\"business_code\"]\n",
    ")\n",
    "nulldata[\"name_customer_enc\"] = label_encoder.transform(\n",
    "    nulldata[\"name_customer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zD9I-XqQwC28",
   "metadata": {
    "id": "zD9I-XqQwC28"
   },
   "source": [
    "### Check for the datatypes of all the columns of Nulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f72517",
   "metadata": {
    "id": "d4f72517"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17cd5452",
   "metadata": {
    "id": "17cd5452"
   },
   "source": [
    "### Now you need to drop all the unnecessary columns - \n",
    "\n",
    "- 'business_code'\n",
    "- \"baseline_create_date\"\n",
    "- \"due_in_date\"\n",
    "- \"posting_date\"\n",
    "- \"name_customer\"\n",
    "- \"clear_date\"\n",
    "- \"cust_payment_terms\"\n",
    "- 'day_of_cleardate'\n",
    "- \"month_of_cleardate\"\n",
    "- \"year_of_cleardate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c82076",
   "metadata": {
    "id": "d7c82076"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Q_NCr9IPweVq",
   "metadata": {
    "id": "Q_NCr9IPweVq"
   },
   "source": [
    "### Check the information of the \"nulldata\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ffee0",
   "metadata": {
    "id": "4e7ffee0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "-XvjhWqmwi-C",
   "metadata": {
    "id": "-XvjhWqmwi-C"
   },
   "source": [
    "### Compare \"nulldata\" with the \"X_test\" dataframe \n",
    "\n",
    "- use info() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4b62d",
   "metadata": {
    "id": "02f4b62d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Us3ey-9zwqjq",
   "metadata": {
    "id": "Us3ey-9zwqjq"
   },
   "source": [
    "### You must have noticed that there is a mismatch in the column sequence while compairing the dataframes\n",
    "\n",
    "- Note - In order to fed into the machine learning model, you need to edit the sequence of \"nulldata\", similar to the \"X_test\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vduVNt1kxPW-",
   "metadata": {
    "id": "vduVNt1kxPW-"
   },
   "source": [
    "- Display all the columns of the X_test dataframe \n",
    "- Display all the columns of the Nulldata dataframe \n",
    "- Store the Nulldata with new sequence into a new dataframe \n",
    "\n",
    "\n",
    "- Note - The code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729353e",
   "metadata": {
    "id": "6729353e"
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd9c5e",
   "metadata": {
    "id": "47bd9c5e"
   },
   "outputs": [],
   "source": [
    "nulldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a2103",
   "metadata": {
    "id": "aa5a2103"
   },
   "outputs": [],
   "source": [
    "nulldata2 = nulldata[\n",
    "    [\n",
    "        \"cust_number\",\n",
    "        \"buisness_year\",\n",
    "        \"doc_id\",\n",
    "        \"converted_usd\",\n",
    "        \"business_code_enc\",\n",
    "        \"name_customer_enc\",\n",
    "        \"cust_payment_terms_enc\",\n",
    "        \"day_of_postingdate\",\n",
    "        \"month_of_postingdate\",\n",
    "        \"year_of_postingdate\",\n",
    "        \"day_of_createdate\",\n",
    "        \"month_of_createdate\",\n",
    "        \"year_of_createdate\",\n",
    "        \"day_of_due\",\n",
    "        \"month_of_due\",\n",
    "        \"year_of_due\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8b021",
   "metadata": {
    "id": "1dc8b021"
   },
   "source": [
    "### Display the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39785a",
   "metadata": {
    "id": "2f39785a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27b88c5a",
   "metadata": {
    "id": "27b88c5a"
   },
   "source": [
    "### Now you can pass this dataset into you final model and store it into \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b6388",
   "metadata": {
    "id": "9e0b6388"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9653d3c6",
   "metadata": {
    "id": "9653d3c6"
   },
   "source": [
    "### you need to make the final_result as dataframe, with a column name \"avg_delay\"\n",
    "\n",
    "- Note - No need to change the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef814d",
   "metadata": {
    "id": "25ef814d"
   },
   "outputs": [],
   "source": [
    "final_result = pd.Series(final_result, name=\"avg_delay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C86staIhyf2C",
   "metadata": {
    "id": "C86staIhyf2C"
   },
   "source": [
    "### Display the \"avg_delay\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd46406",
   "metadata": {
    "id": "4fd46406"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f71a7e",
   "metadata": {
    "id": "44f71a7e"
   },
   "source": [
    "### Now you need to merge this final_result dataframe with the BACKUP of \"nulldata\" Dataframe which we have created in earlier steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0969d",
   "metadata": {
    "id": "e8f0969d"
   },
   "outputs": [],
   "source": [
    "nulldata1.reset_index(drop=True, inplace=True)\n",
    "Final = nulldata1.merge(final_result, on=nulldata.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G-hLtxXgy4GZ",
   "metadata": {
    "id": "G-hLtxXgy4GZ"
   },
   "source": [
    "### Display the \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb4dc0",
   "metadata": {
    "id": "71fb4dc0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4sc27Uz-y-0O",
   "metadata": {
    "id": "4sc27Uz-y-0O"
   },
   "source": [
    "### Check for the Number of Rows and Columns in your \"Final\" dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5iUXOIhzy_HR",
   "metadata": {
    "id": "5iUXOIhzy_HR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48886d2c",
   "metadata": {
    "id": "48886d2c"
   },
   "source": [
    "### Now, you need to do convert the below fields back into date and time format \n",
    "\n",
    "- Convert \"due_in_date\" into datetime format\n",
    "- Convert \"avg_delay\" into datetime format\n",
    "- Create a new column \"clear_date\" and store the sum of \"due_in_date\" and \"avg_delay\"\n",
    "- display the new \"clear_date\" column\n",
    "- Note - Code is given below, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243abc2d",
   "metadata": {
    "id": "243abc2d"
   },
   "outputs": [],
   "source": [
    "Final[\"clear_date\"] = pd.to_datetime(Final[\"due_in_date\"]) + pd.to_timedelta(\n",
    "    Final[\"avg_delay\"], unit=\"s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9QcX_fAjIkYR",
   "metadata": {
    "id": "9QcX_fAjIkYR"
   },
   "source": [
    "### Display the \"clear_date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740e1486",
   "metadata": {
    "id": "740e1486"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "MSkNLq6-z7rZ",
   "metadata": {
    "id": "MSkNLq6-z7rZ"
   },
   "source": [
    "### Convert the average delay into number of days format \n",
    "\n",
    "- Note - Formula = avg_delay//(24 * 3600)\n",
    "- Note - full code is given for this, no need to change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b618a",
   "metadata": {
    "id": "ce6b618a"
   },
   "outputs": [],
   "source": [
    "Final[\"avg_delay\"] = Final.apply(\n",
    "    lambda row: row.avg_delay // (24 * 3600), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wbBBZPjP0W7o",
   "metadata": {
    "id": "wbBBZPjP0W7o"
   },
   "source": [
    "### Display the \"avg_delay\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494982f",
   "metadata": {
    "id": "a494982f",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815d8811",
   "metadata": {
    "id": "815d8811"
   },
   "source": [
    "### Now you need to convert average delay column into bucket\n",
    "\n",
    "- Need to perform binning \n",
    "- create a list of bins i.e. bins= [0,15,30,45,60,100]\n",
    "- create a list of labels i.e. labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
    "- perform binning by using cut() function from \"Final\" dataframe\n",
    "\n",
    "\n",
    "- Please fill up the first two rows of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797e4b5",
   "metadata": {
    "id": "c797e4b5"
   },
   "outputs": [],
   "source": [
    "bins = ___________________\n",
    "labels = __________________________\n",
    "Final[\"Aging Bucket\"] = pd.cut(\n",
    "    Final[\"avg_delay\"], bins=bins, labels=labels, right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35725f",
   "metadata": {
    "id": "1c35725f"
   },
   "source": [
    "### Now you need to drop \"key_0\" and \"avg_delay\" columns from the \"Final\" Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bc6a3",
   "metadata": {
    "id": "b31bc6a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Ui-tyIvU0-5u",
   "metadata": {
    "id": "Ui-tyIvU0-5u"
   },
   "source": [
    "### Display the count of each categoty of new \"Aging Bucket\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e16218",
   "metadata": {
    "id": "a6e16218"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "kgYegy551GKJ",
   "metadata": {
    "id": "kgYegy551GKJ"
   },
   "source": [
    "### Display your final dataset with aging buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc87ec",
   "metadata": {
    "id": "c4bc87ec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Ji7AoDCB1L_x",
   "metadata": {
    "id": "Ji7AoDCB1L_x"
   },
   "source": [
    "### Store this dataframe into the .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d0b8d",
   "metadata": {
    "id": "727d0b8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "FK0fabl61SkC",
   "metadata": {
    "id": "FK0fabl61SkC"
   },
   "source": [
    "# END OF THE PROJECT"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "62633a84"
   ],
   "name": "Payment date prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}